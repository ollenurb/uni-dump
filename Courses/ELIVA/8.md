# Visione Artificiale con Reti Neurali
In questo capitolo ci si concentrerà sulla visione artificiale, interamente per
mezzo di approcci machine learning, nello specifico mediante l'impiego di reti
neurali profonde. Inoltre, ci si concentrerà su problemi di apprendimento
supervisionato come la **classificazione** o la **regressione**.

## Apprendimento Supervisionato
Un esempio di problema di apprendimento supervisionato nel campo della computer
vision potrebbe essere quello di classificare con una determinata classe un
oggetto presente in un immagine. Ad esempio, se un immagine contiene un gatto
oppure un cane.
Il dataset di input per un problema di apprendimento supervisionato è
rappresentato da una matrice $\mathbf{X}$ con tante righe quante istanze
presenti nel dataset e tante colonne quante *features* del problema. Inoltre si
indicano le classi etichettate delle varie istanze con il vettore $\mathbf{t}$.
Si supporrà inoltre che i dati siano normalizzati, cioè tali per cui abbiano
media $\mu = 0$ e varianza $\sigma = 1$. Formalmente, per ogni vettore colonna
$\mathbf{x}_i$, si applica la seguente formula:
$$
\mathbf{x}_i = \frac{\mathbf{x}_i - \mu(\mathbf{x}_i)}{\sigma(\mathbf{x}_i)}
$$

## Percettrone
La rete più semplice che si può immaginare è quella composta da un singolo
neurone. Esso ha una serie di input $x_i$, una serie di parametri (*pesi*)
$w_i$, un *bias* additivo e una funzione di attivazione *non-lineare* e
differenziabile $g$.
Si prende ispirazione dal funzionamento biologico di un neurone del sistema
nervoso, che consiste nel rappresentare un neurone come una funzione che somma i
semplicemente vari segnali in input (i neuroni ai quali è connesso) pesandoli
per la forza di connessione che ha il neurone con essi. Questa somma poi viene
fatta passare per una funzione di attivazione che indica la risposta del
neurone, siccome nei neuroni biologici esiste una soglia di attivazione. 

Mettendo insieme questi componenti, otteniamo che l'output del neurone è
rappresentabile come
$$
y = g \left (b + \sum_{i} \mathbf{w}_i \mathbf{x}_i \right )
$$

L'apprendimento di questa semplice rete consiste inizialmente nell'impostare i
valori dei pesi $\mathbb{w}$ in modo completamente casuale. Successivamente, si
calcola per ogni istanza di input $\mathbf{x}_i \in X$ (*vettore riga*) l'output
$y_i$ corrispondente del neurone. A questo punto si calcola un errore $E$
differenziabile $t_i$, come il Mean Square Error $E_i(y_i, t_i) = (y_i -
t_i)^2$. Siccome sia l'errore che l'output del neurone sono differenziabili, è
possibile calcolare il *gradiente* dell'errore $\frac{\partial E}{\partial
\mathbf{w}}$. Il calcolo del gradiente può essere fatto semplicemente per mezzo
della regola di derivazione a catena. Difatti, espandendo la definzione di $E$
si ottiene:
$$
E(y_i, t_i) = \left [ g \left ( \underbrace{b + \sum_{j} \mathbf{w}_j \mathbf{x}_ij }_{z_i} \right ) - t_i
\right ]
$$
Quindi, per la formula di derivazione a catena il gradiente corrispondente sarà:
$$
\frac{\partial E}{\partial \mathbf{w}_i} = 
\frac{\partial E}{\partial y_i}
\frac{\partial y_i}{\partial z_i}
\frac{\partial z_i}{\partial \mathbf{w}_i}
$$
dove $z_i$ è indicato nella formula precedente.

Una volta ottenuto il gradiente, per ogni $\mathbf{w}_i$ si applica una regola
di update secondo il principio di *discesa del gradiente*. Essenzialmente questo
principio permette di minimizzare l'errore modificando i pesi in modo da
muoversi verso la direzione opposta all'aumento più grande dell'errore (e
quindi, di conseguenza, verso la massima diminuizione). Dal punto di vista
formale, la regola di update è la seguente:
$$
\mathbf{w}'_i = \mathbf{w}_i - \eta \frac{\partial E}{\partial \mathbf{w}_i}
$$
in cui $\mathbf{w}'_i$ è il nuovo valore del peso $i$-esimo e $\eta$ è un
iperparametro dell'ottimizzatore che indica il *learning rate* (o *step-size*).
Questo passaggio viene re-iterato per tutte le istanze $i$ del dataset,
completando di fatto un *epoca*.

## Fully Connected Layer
Il percettrone, pur rappresentando un fondamentale punto di partenza nel campo
delle reti neurali, presenta alcune limitazioni. Come visto, difatti,
rappresenta solo un output scalare $y$. È possibile concatenare diversi
percettroni per ottenere un FCL (*Fully Connected Layer*). In caso se ne
concatenino $m$, si otterranno $m$ vettori $\mathbf{w}$ di parametri, per cui
vengono rappresentati tutti in una matrice $\mathbf{W}$ con dimensioni $m \times
n$ dove $m$ è il numero di outputs (*percettroni*) e $(n+1)$ il numero di inputs
(dove il $+1$ può essere omesso e rappresenta il *bias*).

## Multilayer Perceptron
Un layer completamente connesso permette di "mappare" le features in input su un
nuovo spazio vettoriale. Concatenare vari layer uno dopo l'altro permette di
"processare" l'informazione in input, mappandola in diversi spazi vettoriali.
Ciò che la rete fa è essenzialmente apprendere delle features latenti del
dataset che possono essere utilizzate per discriminare dei problemi anche non
linearmente separabili (poiché esse lo sono). In un problema di
multi-classificazione, l'ultimo layer sarà composto da tanti neuroni quanti sono
le classi che fanno parte del problema di classificazione, poiché i vari neuroni
fungeranno da classificatori per la stessa classe. Inoltre, in questo tipo di
problemi si applica una funzione *softmax* sul vettore dei neuroni di output
$\mathbf{z}$, per cui l'output della rete sarà
$$
\mathbf{y} = \frac{e^{\mathbf{z}}}{\sum_{k=1} e^{z_k}}
$$
La probprietà della softmax è che crei una *distribuzione* sulle varie
componenti del vettore, che in questo caso sono le varie classi. Per questo è
possibile calcolare una metrica di errore che funziona meglio per problemi di
classificazione, cioè la *cross-entropy loss*:
$$
\mathscr{L}(\mathbf{y}, \mathbf{t}) = -\sum_j t_j log(y_j)
$$

### Overfitting
Più aumenta la complessità del modello (numero di layer e neuroni), più esso
sarà in grado di adattarsi al il dataset di train iniziale. Bisogna però fare
attenzione al tradeoff bias-variance. Un classificatore troppo coomplesso si
adatterà troppo ai dati, provocando *overfitting* (cioè un fenomeno in cui il
classificatore modella così bene i dati di input che non è in grado di
generalizzare). Tipicamente si introduce una regolarizzazione dei pesi in normal
$\mathscr{L}^2$ in modo tale da penalizzare le soluzioni con valori dei pesi
troppo grandi.

In un problema di machine learning, per capire se ci si trova di fronte ad un
modello overfitted, si divide il dataset originale in dataset di train e dataset
di test. Si apprende il modello sullo split del dataset di train e si testa su
quello di test. L'overfit si verifica quando l'errore di train è più alto
dell'errore di test.  

## Reti Feed Forward e Immagini
Fino ad ora si è supposto che le features di un problema di classificazione
fossero delle qualità intrinseche che potessero rappresentare le varie istanze,
come ad esempio il peso, l'altezza, la grandezza ecc.
Viene naturale pensare che le immagini stesse possano essere viste come un
insieme di features, cioè ogni valore di pixel rappresenterebbe di per se una
feature. In questo senso, un'immagine $N \times M$ può essere rappresentata in
un vettore lungo $N \cdot M$, con i valori delle features corrispondenti ai
valori di intensità dei pixel. Nel dataset MNIST, composto da immagini $28
\times 28$ di cifre scritte a mano ed etichettate con la classe corretta
($0-9$), le immagini sono per l'appunto espresse in vettori lunghi $28 \cdot 28
= 768$ elementi.

### LeNet 300
LeNet 300 fu un'architettura introdotta alla fine degli anni 80 per fare
riconoscimento di cifre scritte a mano e classificarle (*handwritten digit
recognition*). La rete era una rete completamente connessa (composta da soli
layer fully connected), la cui architettura era composta da:

* Input layer di dimensioni $768$ (il che è ragionevole poiché l'input sono
  immagini lunghe $768$);
* Layer hidden di dimensioni $300$;
* Layer hidden di dimensioni $100$;
* Layer di output di dimensioni $10$ (il numero di classi che coincide con il
  numero di cifre).

Nel paper originale venivano fatte diverse esplorazioni di parametri
dell'architettura, ma quella con performare migliori fu appunto quella
presentata precedentemente. 
Il problema di questo approccio è che questo tipo di rete non permette di
sfruttare la correlazione spaziale dei pixel che esiste in un'immagine
qualsiasi. Questo perché le immagini sono trattate semplicemente come dei
vettori, rimuovendo di fatto questa struttura bidimensionale e di conseguenza
l'informazione spaziale che ne consegue.

## Reti Neurali Convoluzionali
Le reti convoluzionali sono un'evoluzione di questo approccio, nate per
l'appunto per risolvere questa problematica e sfruttare la correlazione spaziale
dei pixel nelle immagini.



