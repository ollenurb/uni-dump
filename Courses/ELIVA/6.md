# Image Enhancement (Dominio di Fourier) TODO: AGGIUNGERE FILTRO BUTTERWORTH
Reiterando quello che è stato visto nel capitolo precendente, nel dominio di
Fourier vengono rappresentate le informazioni che riguardano l'intesità di
*pattern* presenti nell'immagine (ad esempio, $F(0,0)$ contiene il valore medio
dell'immagine). Quando facciamo image enhancement nel dominio di Fourier è
necessario sempre considerare dei filtri che siano *simmetrici* rispetto
all'origine. In caso contrario, quando si ricostruisce l'immagine elaborata si
otterrebbero valori complessi.

> **Importante**: come già detto, i filtri già visti che operano nel dominio dello
> spazio sono interpretabili anche nel dominio delle frequenze, eccetto però i
> filtri *non-lineari*. La trasformata di Fourier, infatti, permette di
> implementare solo filtri che sono lineari, per cui, il filtro *mediano* ad
> esempio non è implementabile nel dominio delle frequenze (così come tutti i
> filtri che coinvolgono ad esempio un ordinamento).

L'unica cosa che considereremo sarà lo *spettro* (modulo) della trasformata,
dimenticandoci in un certo senso della fase, che supporremo nulla in tutto il
dominio (come già discusso, rimane però di centrale importanza).

Possiamo riassumere il processamento nel dominio delle frequenze nei seguenti
passaggi:
$$
f_{elab}(x, y) = \mathscr{F}^{-1}[H(u, v)F(u, v)]
$$
da cui sono evidenti i singoli passaggi per effettuare l'elaborazione:

1. Trasformazione dell'immagine e del filtro tramite DFT;
2. Filtraggio delle frequenze per mezzo della moltiplicazione dell'immagine
   traformata e del filtro trasformato;
3. Ricostruzione dell'immagine elaborata tramite trafrormata inversa (IDFT).

## Esempi di Filtri

### Mean Removal
Consideriamo ad esempio il seguente filtro
$$
H(u, v) = 
\begin{cases}
0 & u = v = 0\\
1 & \text{otherwise}
\end{cases}
$$
Tale filtro va a rimuovere tutte le componenti *continue*, cioè dove i valori
non cambiano tra loro e quindi sono uniformi essendo che hanno frequenza pari a
0. Il risultato di questa applicazione è che l'immagine risultante sarà a media
nulla, cioè la media di tutti i valori di pixel sarà 0.

### Filtri passa alto/basso ideali
Altri filtri degni di nota sono i filtri *passa alto* e *passa basso*. Il primo
cancella del frequenze basse, per cui va ad accentuare essenzialmente i bordi
riducendo l'intensità nelle zone omogenee. L'effetto del secondo è invece
l'opposto, per cui si ottengono delle operazioni di *smoothing* dell'immagine.
Un filtro passa basso ideale è implementato nel modo seguente:
$$
H(u, v) = 
\begin{cases}
1 & \text{if } D(u, v) \leq D_0\\
0 & \text{if } D(u, v) > D_0\\
\end{cases}
$$
dove la funzione $D$ indica la *distanza* di un punto dal centro:
$$
D(u, v) = \sqrt{ \left ( u - \frac{P}{2} \right )^2 + \left ( v - \frac{Q}{2} \right )^2 }
$$
Di solito, in realtà, per fare processamento di immagini si preferisce mantenere
il processing a livello spaziale. Quindi la fase di progettazione del filtro
avviene nel dominio delle frequenze, per poi fare una IDF del filtro e ottenere
la sua versione spaziale. Se suppponessimo di voler progettare un filtro passa
basso ideale (rappresentato in una dimensione da una funzione rettangolare), ci
scontreremo però subito con un problema: il *ringing*.
L'idealità di un filtro passa-basso/alto nella frequenza compromette l'idealità
nello spazio e viceversa. Questo può essere spiegato semplicemente guardando
l'antitrasformata di un filtro rappresentato da una funzione a rettangolo, in
cui ci sono diverse oscillazioni che generano rumore. Per andare a rappresentare
un cambio brusco (continuo) il filtro risultante è infinito in dominio (funzione
*sinc*). Perciò di solito si tende a "tagliarlo" oltre una certa soglia per
renderlo utilizzabile (di solito i filtri hanno dimensioni molto più piccole
delle immagini). Ciò che si ottiene, è evidente andando a fare la trasformata di
questo filtro ottenuto, che conterrà meno sinusoidi e quindi conterrà una
versione distorta della funzione a rettangolo con diversi artefatti introdotti
dalle interazioni delle cosinusoidi. Questo perché avendo rimosso alcuni valori
della funzione nel dominio dello spazio (andando a tagliarla) si vanno
effettivamente a rimuovere delle informazioni cruciali (meno campioni) per
ricostruire la funzione rettangolo nel dominio delle frequenze. Come già detto,
il fenomeno che introduce queste discontinuità è detto *ringing*.

### Gaussiano
Siccome questo problema viene dato dalla *discontinuità* del filtro (cioè non è
derivabile nei punti in cui cambia di valore), si potrebbe evitare utilizzando
un'approssimazione differenziabile di tale filtro. Una possibile funzione per
implementare il filtro passa basso è la curva *Gaussiana*.
$$
H(u) = A e^{-u^2/2 \sigma^2}
$$
La cosa interessante della gaussiana è che è invariante rispetto alla
trasformata. L'unica cosa che cambia è la forma:

* Se $\sigma$ è grande, allora la trasformata sarà larga e l'antitrasformata
  stretta;
* Se $\sigma$ è piccolo, allora la trasformata sarà stretta e l'antitrasformata
  larga.

Se volessimo invece implementare un filtro passa basso, possiamo *invertire* la
Gaussiana
$$
H(u) = 1 - A e^{-u^2/2 \sigma^2}
$$
L'unico problema della Gaussiana è che risulta difficile andare a rimuovere
totalmente alcune frequenze, non essendo mai a 0.

La parte di Image Enhancement vista fin'ora è funzionale a due grandi classi di
elaborazione d'immagini. La più grande è il miglioramento soggettivo
dell'immagine (ad esempio, per la visualizzazione). La seconda, invece, è quella
di utilizzare l'enhancement come fase di pre-processing in una pipeline di
elaborazione delle immagini.

### Laplaciano
Il Laplaciano che abbiamo visto precedentemente è rappresentabile anche nel
dominio delle frequenze. È molto più semplici difatti fare la derivata nel
dominio delle frequenze rispetto allo spazio.
$$
\nabla^2 f(t, z) = \frac{\partial^2 f(t, z)}{\partial t^2} \frac{\partial^2 f(t, z)}{\partial z^2}
$$
La derivata della trasformata corrisponde a moltiplicare le trasformate per
$(j2\pi u)^2$:
$$
\mathscr{F}[f(t, z)] =(j2\pi u)^2 \cdot F(u, v) + (j2\pi u)^2 \cdot F(u, v) =
-4\pi^2 (u^2 + v^2) F(u, v)
$$
per cui il filtro nel dominio delle frequenze sarà
$$
H(u, v) = -4\pi^2 (u^2 + v^2) 
$$
il cui grafico del modulo rappresenta una *"coppa"*, per cui si tratta di un
filtro *passa-alto*.
Siccome il filtro "parte" dall'angolo in alto a sinistra $(0, 0)$, si preferisce
sempre fare una traslazione in modo che sia al centro dell'immagine 
$$
H(u, v) = -4 \pi^2 \left [ \left ( u - \frac{P}{2} \right )^2 + \left ( v - \frac{Q}{2} \right )^2 \right ] = -4\pi^2 D^2(u, v)
$$
dove
$$
D^2(u, v) = \sqrt{ \left ( u - \frac{P}{2} \right )^2 + \left ( v - \frac{Q}{2} \right )^2 }
$$
Si ricorda l'applicazione del Laplaciano vista nei capitoli precedenti
$$
g(x, y) = f(x, y) + c \nabla^2 f(x, y)
$$
per cui, se volessimo calcolarlo nel dominio delle frequenze
$$
\begin{split}
g(x, y)
& = \mathscr{F}^{-1}[F(u, v) - H(u, v)F(u, v)]\\
& = \mathscr{F}^{-1}[F(u, v) - (c + 4\pi D^2(u, v))]
\end{split}
$$
implementare lo sharpening in frequenza corrisponde quindi a moltiplicare per un
filtro che ha le sembianze di una coppa rovesciata traslata rispetto all'asse
$z$ di $c$, per cui lascia passare il valor medio in maniera proporzionale al
valore di $c$. Il risultato dell'applicazione di questo filtro sono effetti in
cui il valor medio permane, esaltando però i valori di alta frequenza (texture,
bordi, pattern). 

### Filtraggio Omomorfico
È un tipo di filtering che serve a migliorare l'immagine in cui l'illuminazione
non è soddisfacente. Si parte da un *modello* che descrive l'immagine, secondo
il quale essa è caratterizzata da 2 componenti
$$
f(x, y) = i(x, y)r(x, y)
$$
dove:

* $i(x, y)$ è la luminosità del pixel, cioè il valore con cui il pixel in
  questione *riceve* la luce;
* $r(x, y)$ è la riflettanza, cioè il valore con cui il pixel in questione
  *riflette* la luce ricevuta.

La riflettanza descrive la *scena*, cioè gli oggetti presenti nell'immagine.
Assumiamo nella maggior parte dei casi che ci si interessi solo l'oggettività
della scena, cioè degli oggetti presenti nella scena. L'obiettivo è quello di
rendere uniforme la luminosità dell'immagine, cioè in modo tale che tutta la
scena sia illuminata in modo uniforme, senza che alcune zone siano più o meno
illuminate di altre. Possiamo sfruttare il fatto che la componente luminosa non
ha variazioni significative all'interno dell'immagine (alte frequenze), per cui
l'idea è quella di applicare un filtro high-pass alla componente $i$ e nessun
filtro a $r$. Per evitare difficoltà e separare le due componenti che sono due
prodotti (anche perché per il teorema della convoluzione, la trasformata di un
prodotto diventerebbe una convoluzione), si utilizza un *"trucco"* matematico
che consiste nel considerare il *logaritmo* dell'immagine, cosicchè il prodotto
diventi la somma dei logaritmi delle componenti, formalmente
$$
z(x, y) = \log f(x, y) = \log i(x, y) + \log r(x, y)
$$
quindi, la trasformata sarà ugualmente semplice
$$
Z(u, v) = F_i(u, v) + F_r(u, v)
$$
a questo punto si può filtrare nello spazio delle frequenze
$$
S(u, v) = H(u, v) Z(u, v) = H(u, v)F_i(u, v) + H(u, v)F_r(u, v)
$$
l'immagine elaborata (in scala logaritmica) sarà ovviamente l'antitrasformata di
$S$, il che è composta per definizione dalla componente $i'$ elaborata e dalla
componente $r'$ elaborata:
$$
s(x, y) = \mathscr{F}^{-1}[S(u, v)] = i'(x, y) + r'(x, y)
$$
l'algoritmo termina andando a rimuovere i logarimi, tornando alla scala normale,
semplicemente facneod l'esponenziale di $s$:
$$
g(x, y) = e^{s(x, y)} = i_0(x, y) r_0(x, y)
$$

Come detto in precedenza, il filtro $H$ deve andare ad agire solamente sulla
componente luminosa $i$ ed è descritto dalla seguente formula:
$$
H(u, v) = (\gamma_H - \gamma_L) \left( 1 - e^{-c(D^2(u, v)/D_0^2)}\right) +
\gamma_L
$$

questo filtro effettua essenzialmente uno sharpening al dominio logaritmico.
Dalla formula, se:

* $\gamma_L < 1$ vengono attenuate le basse frequenze (illuminazione);
* $\gamma_H > 1$ vengono amplificate le alte frequenze (riflettanza), aumentando
  il contrasto.

### Gaussian Pyramid
Per evitare di fare aliasing durante il downsampling (riduzione delle dimensioni
dell'immagine), si può applicare un filtro passa basso a metà della frequenza
(corrisponde essenzialmente al filtro $D^2$ in cui $D_0 = f/2$, ovviamente però
si usa un Gaussiano o un qualsiasi altro filtro passa basso realizzabile).

Questa operazione di downsampling non sono è utile per fare un'operazione di
resizing, ma serve per costruire delle rappresentazioni multi-risoluzione. Un
idea è appunto quella di catturare un'immagine e poterla elaborare a diversi
stadi di risoluzione. Un tipo di applicazione è ad esempio Google Earth, dove
ovviamente non possono essere caricate tutte le immagini di risoluzione massima
in tutta la memoria dell'intero globo, ma in base alla distanza viene aumentata
la risoluzione su particolari zone di dettaglio. Un'altro approccio può essere
quello di applicare diverse elaborazioni di Computer Vision a diverse
risoluzioni per aumentare la precisione degli algoritmi.

Per gestire le varie risoluzioni dell'immagine si utilizza una struttura dati a
*piramide*, rappresentata da un formato `TIFF`. La piramide si costruisce
partendo dalla piena risoluzione e facendo mano a mano una *cascata* di resizing
(applicando un filtro low pass e un successivo downsampling, mantenendo
essenzialmente un pixel si e uno no per righe e per colonne). Se l'operazione di
downsampling è implementato per mezzo di un filtro Gaussiano, questa struttura
viene chiamata *Piramide Gaussiana* (Gaussian Pyramid).

### Laplacian Pyramid
Un'altro esempio di struttura è la *Piramide Laplaciana*. Al posto di
memorizzare ogni immagine sottocampionata, l'idea è invece quella di andare a
memorizzare l'*errore* (opportunamente pre-calcolato) che viene commesso
considerando una versione a bassa risoluzione dell'immagine e scalandola per
mezzo di un'interpolazione al livello successivo della piramide (ad esempio,
$\times 2$). In questo caso, l'errore riguarda maggiormente le alte frequenze,
poiché facendo questa interpolazione si perdono tutti i dettagli riguardandi i
bordi ad esempio. Quindi, l'idea è quella di memorizzare questi dettagli persi
(che sono di fatto il Laplaciano dell'immagine), in modo tale che quando
l'immagine viene scalata per mezzo dell'interpolazione, si possono aggiungere
questi dettagli, semplicemente sommandone il Laplaciano corrispondente.

La costruzione di un singolo step di questa piramide viene fatto per mezzo dei
seguenti passaggi:

1. Parto dalla immagine in input (al primo step sarà l'immagine a risoluzione
   piena) e ne faccio il downsample ottenendo un'immagine a grandezza dimezzata.
2. Partendo dall'immagine downsampled al passo precedente, ne faccio upsampling
   per mezzo di un metodo di interpolazione[^longnote] in modo da tornare alle
   dimensioni di partenza.
3. Si calcola la discrepanza tra l'immagine upsampled (risultato) e l'immagine
   originale (ground truth), semplicemente facendone la differenza.
4. Si reitera il processo prendendo come immagine di input l'immagine ottenuta
   facendo downsampling.

[^longnote]: Per fare interpolazione si prende l'immagine upsampled composta dai
  pixel dell'immagine con i pixel mancanti posti a 0 (alternano tra pixel a 0 e
  pixel dell'immagine), e successivamente si applica un filtro Gaussiano per
  fare smoothing.

A questo punto, in memoria saranno memorizzate solo 2 componenti:

1. L'ultimo step di downsample, quindi l'immagine con risoluzione più bassa;
2. I vari errori (dettagli, Laplaciani) ottenuti in ogni step della piramide.

Tutte queste componenti hanno l'informazione necessaria e sufficiente a
ricostruire tutte le varie risoluzioni, fino ad arrivare a quella di partenza.
L'idea è quella già discussa; si parte semplicemente dal primo step, si fa
interpolazione ottenendo una versione upsampled, e poi si somma il dettaglio
corrispondente a quello step particolare. Ovviamente, per ottenere l'immagine a
step $n$, devono essere ripercorsi tutti gli step precedenti, partendo
dall'immagine originale.

La differenza tra piramide Gaussiana e Laplaciana è essenzialmente un trade-off
tra tempo computazionale e memoria. Mentre la prima è meno efficiente dal punto
di vista della memoria, non deve utilizzare nessuna elaborazione per fare
retrieval di una determinata immagine ad una determinata risoluzione. D'altra
parte, la piramide Laplaciana, è più efficiente in termini di memoria ma deve
andare a fare una serie di step per recuperare l'immagine alla risoluzione
desiderata, per cui è meno efficiente dal punto di vista computazionale.

Un'applicazione della piramide Laplaciana che abbiamo visto è il *matting*, cioè
il blending di due immagini tra loro (metà e metà ad esempio). Con il *pyramid
matting* si intende una tecnica che utilizza la piramide Laplaciana per fare un
matting più *smooth* rispetto ad un matting netto.

### Altri Filtri
L'idea alla base di questi filtri è esprimere queste funzioni in termini della
distanza rispetto all'origine
$$
D(u, v) = \sqrt{\left( u - \frac{P}{2}\right)^2 + \left( v - \frac{Q}{2}\right)^2}
$$

#### Esponenziale
Il filtro esponenziale è rappresentato nel modo seguente:
$$
H(u, v) = e^{-[D(u, v)/D_0]^n}
$$
Dove i parametri sono $D_0$ (*cutoff frequency*) e $n$, che controlla quanto è
accentuata la transizione. Valori alti indicano transizioni alte.

#### Trapezoidale
Questo filtro ha essenzialmente due parametri:

* $D_0$ la banda passante;
* $D_1$ la banda di taglio (*cutoff frequency*). 

Con $D_0 < D_1$. La regione delimitata da $D_0$ e $D_1$ viene detta *cutoff
region*. Il filtro (cross section) in prossimità di $D_0$ ha valore $1$, mentre
ha valore $0$ in prossimità di $D_1$.

#### Bandreject/Bandpass
Questi filtri vanno a processare delle bande specifiche di frequenza, non solo
alte o basse. I filtri bandreject possono essere implementati come i filtri che
sono stati visti in precedenza: ideale, Butterworth e Gaussiano. Hanno però 2
parametri addizionali:

* $D_0$ che indica il punto di *cutoff* in cui sarà centrato il filtro, cioè il
  punto in cui viene centrata la finestra che delimita la banda di frequenza da
  rimuovere;
* $W$ indica la larghezza totale della finestra.

Di seguito sono riportate le varie implementazioni dei filtri bandreject.

* **Ideale**:
  $$
  H(u, v) = 
  \begin{cases}
  0 & \text{if } D_0 - \frac{W}{2} \leq D \leq D_0 + \frac{W}{2}\\
  1 & \text{otherwise}
  \end{cases}
  $$
* **Butterworth**:
  $$
  H(u, v) = 
  \frac{1}{1 + \left[ \frac{DW}{D^2 - D^2_0} \right]^{2n}}
  $$
* **Gaussiano**:
  $$
  H(u, v) = 
  1 - e^{\left[ -\frac{D^2 - D^2_0}{DW} \right]}
  $$

Ovviamente, l'equivalente filtro passabanda si ottiene per simmetria del
bandreject, ovvero
$$
H_{BP}(u, v) = 1 - H_{BR}(u, v)
$$

#### Filtri Notch
Sono una famiglia di filtri che si concentrano su specifiche zone di frequenza.
In questo senso, vanno a rimuovere o far passare (o incentivare) le frequenze in
alcune aree del rettangolo (filtro). Ovviamente, come ogni filtro, per essere
valido deve essere simmetrico rispetto all'origine.
Questi filtri non sono più specificati per un range come i filtri visti
precedentemente, ma per delle specifiche frequenze $(u_k, v_k)$ (nel caso
bi-dimensionale). Di queste frequenze possono esserne processate una moltitudine
$(u_1, v_1), (u_2, v_2), \dots, (u_S, v_S)$, ognuna differente dall'altra.
Siccome si vuole processare differentemente una singola frequenza, si associa un
filtro differente per ognuna $H_k(u, v)$, centrato nel punto $(u_k, v_k)$
corrispondente, che effettuerà il processing voluto per la frequenza $k$-esima.
A questo punto, il filtro Notch è definito dalla concatenazione dei vari filtri
$$
H_{NR}(u, v) = \prod^S_{k = 1}H_k(u, v)H_{-k}(u, v)
$$
dove $H_{-k}$ viene inserito per non rompere la simmetria del filtro.
I filtri $H_k$ utilizzati sono tipicamente Gaussiani o Butterworth, per evitare
i problemi (*ringing*) discussi in precedenza dei filtri ideali.

Per scrivere l'espressione eplicita dei filtri bisogna fare però qualche
accortezza nel definire la distanza, poiché sarà rispetto al nuovo centro $(u_k,
v_k)$ del singolo filtro $H_k$. La distanza sarà quindi (assumendo il centro
dell'immagine essere $(M/2, N/2)$):
$$
D_k(u, v) = \sqrt{(u - M/2 - u_k)^2 + (v - N/2 - v_k)^2} 
$$
A questo punto, se volessimo un filtro Notch-reject Butterworth avremmo
$$
H_{NR}(u, v) = \prod^{S}_{k=1} \left[ \frac{1}{1 + (D_{0k}/D_k(u, v))^{2n}} \right] \left[ \frac{1}{1 + (D_{0k}/D_{-k}(u, v))^{2n}} \right]
$$
in cui $D_{0k}$ sono le *cutoff frequencies* di ogni filtro $H_k$, che posono
essere ovviamente tutte diverse.
Così come tutti gli altri filtri, se volessimo invece un Notch-pass:
$$
H_{NP}(u, v) = 1 - H_{NR}(u, v)
$$
Uno degli esempi visto in cui è utile il Notch Filter è rimuovere pattern
periodici tipo Moiré patterns, oppure pattern periodici anche solo in una
particolare direzione. Questo processing si avvicina quindi molto al task di
restoration.
