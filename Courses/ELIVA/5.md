# La trasformata di Fourier

## Introduzione
L'idea alla base dello studio dei segnali periodici di Fourier è che ogni
funzione **periodica** può essere scritta come la **somma** di *seni* e
*coseni*, di differenti *ampiezze* e *frequenze* (in caso solo un tipo di
funzione venga utilizzato - seno o coseno - allora si utilizza anche la *fase*).
Questa somma viene chiama **serie di Fourier**. 

Nel caso invece delle funzioni **non-periodiche**, si possono rappresentare come
un *integrale* di *seni* e *coseni* pesati (da un'opportuna funzione). Questa
rappresentazione viene invece chiamata **trasformata di Fourier**.

> *La rappresentazione nel **dominio di Fourier** è *equivalente*
> all'originale.*

## La serie di Fourier
Come già citato in precedenza, ogni funzione periodica di periodo $T$ (o
equivalentemente di frequenza $\omega = \frac{2 \pi}{T}$) può essere espresso
come
$$
f(t) = \sum^{\infty}_{n = -\infty} c_n e^{j\omega n t} \quad \text{ con } n\in
\mathbb{Z}
$$
dove i coefficienti calcolati con la seguente formula
$$
c_n = \frac{1}{T} \int^{T/2}_{-T/2} f(t) e^{-j \omega nt} dt
$$
i coefficienti vanno ad indicare *quanto* la frequenza fondamentale $\omega n$ è
presente all'interno del segnale $f(t)$. In altri termini, questo integrale va a
calcolare la similarità tra il segnale *"sonda"* $f(t)$ e la frequenza
fondamentale $e^{j\omega nt}$.

> **Formula di Eulero**: $e^{j \omega} = cos(\omega) + j sin(\omega)$

Si noti che $T$ indica la *risoluzione* della pulsazione in frequenza. Tanto più
$T$ è grande, tanto più sarà grande.

## La trasformata di Fourier
Per fare da *"ponte"* tra la serie e la trasformata di Fourier, è necessario
introdurre un concetto fondamentale: la distribuzione *delta di Dirac*. Tale
funzione (più correttamente *distribuzione*) è caratterizzata da un impulso di
ampiezza infinita e di una durata infinitamente piccola (puntuale), ed è
definita matematicamente nel modo seguente
$$
\delta(t) = 
\begin{cases}
\infty & \text{if } t=0\\
0 & \text{otherwise}
\end{cases}
$$
inoltre, essendo una distribuzione deve valere che
$$
\int_{-\infty}^{\infty} \delta(t) dt = 1
$$
ha una proprietà molto importante detta *shifting property* (oppure *sampling
property*) tale per cui, presa una funzione $f(t)$ e moltiplicata per la *delta
di Dirac*, ne ritorna il valore al punto $0$ (in generale, nel punto in cui è
centrata la funzione $\delta$). Tale proprietà generale è riassumibile nel modo
seguente
$$
\int_{-\infty}^{\infty} f(t) \delta(t - u) dt = f(t - u)
$$
L'intuizione è che siccome la distribuzione $\delta$ è 0 ovunque tranne che
intorno ai valori $t-u$, l'integrale anche è nullo per cui si possono
considerare solo gli estremi di integrazione in un intorno infinitesimamente
piccolo di $t-u$. In questo intorno la funzione $f(t - u)$ non cambia, per cui è
costante e può esser portata fuori dall'integrale. A questo punto, l'integrale
della distribuzione $\delta$ è 1, per cui ne deriva la dimostrazione.

È importante notare che questa proprietà vale anche nel discreto, creando di
fatto una connessione tra la trasformata e la serie che verrà discussa più
avanti.

Avendo introdotto tutto il necessario, per ottenere la trasformata dalla serie
facciamo tendere (nella definizione di serie di Fourier) $T \rightarrow \infty$.
Focalizzandosi inizialmente solo sul calcolo dei coefficienti $c_n$, notiamo in
primo luogo (dalla definizione data precedentemente), che l'estremo di
integrazione diventa da $-\infty$ a $+\infty$. Inoltre, la variabile discreta
$n$, siccome è divisa per $T$, indica delle frequenze arbitrariamente vicine,
per cui $\frac{n}{T}$ viene sostituito da una variabile continua $u$. Infine, il
termine moltiplicativo $\frac{1}{T}$ diventa per definizione il *differenziale*
dell'integrale $dt$. Otteniamo quindi la cosiddetta **trasformata** di Fourier,
riportata in seguito
$$
F(u) = \int^{-\infty}_{+\infty} f(t) e^{-j 2\pi ut} dt
$$
Si noti che la funzione $F(u)$ è in funzione della *frequenza*, ed equivale alla
rappresentazione di $f$ nel dominio delle *frequenze*. È possibile anche
definire la trasformata inversa, semplicemente applicando lo stesso processo al
limite alla definizione della *serie*, e sostituendo le definizioni dei
coefficienti con la definizione di trasformata
$$
f(t) = \int^{-\infty}_{+\infty} F(u) e^{j 2\pi ut} du
$$
tra la trasformata e l'inversa cambia solo il segno dell'esponenziale, per cui
si dice che la trasformata rispetta la proprietà di **simmetria**.

Un'altra proprietà importante della trasformata di Fourier è che nonostante
individui tutte le frequenze presenti in un segnale, le informazioni di tipo
*spaziale* (o *temporale* nel caso di segnali nel tempo) vengono perse. Questo è
dimostrabile considerando la trasformata di un segnale qualunque traslato poiché
il risultato (in modulo) non cambia rispetto al segnale non traslato (dettagli
matematici sule slides).

### Trasformate importanti

#### Funzione Rettangolo
Una delle poche funzioni di cui è necessaria una certa dimestichezza con la sua
trasformata è la funzione $sinc$. Per introdurla, prendiamo un segnale a
finestra (potrebbe, per esempio, essere una riga di pixel) definita nel modo
seguente
$$
f(t) = 
\begin{cases}
A &\text{for } -a \leq t \leq a\\
0 &\text{otherwise}
\end{cases}
$$
La trasformata $F$ di tale funzione è la cosiddetta *funzione sinc*:
$$
F(u) =
\int_{-a}^{+a} A e^{-j 2\pi u t} dt =
\left [ \frac{A}{-2j\pi u} e^{-2\pi u t} \right ]_{-a}^{a} =
\frac{sin(2a\pi u)}{2a\pi u} = 
a \cdot A \cdot sinc(2a u)
$$

> *Graficamente, la funzione $sinc$ ha valore $1$ in $u=0$, e oscilla con $u
  \rightarrow \infty$ avvicinandoci asintoticamente all'asse $x$.*

Ovviamente, possiamo anche definire la trasformata per segnali bi-dimensionali,
per cui la trasformata di un segnale rettangolare bi-dimensionale (ad esempio
una porzione d'immagine) in questo caso sarebbe una funzione $sinc$
bi-dimensionale.

#### Delta di Dirac
Vale la pena considerare anche la trasformata della funzione $\delta$ introdotta
precedentemente, poiché ha diverse caratteristiche degne di nota.
$$
F(u) = \int^{-\infty}_{+\infty} \delta(t) e^{-j 2\pi ut} dt = e^{-j 2 \pi u 0} =
1
$$
il fatto che la trasformata sia la funzione costante $1$, indica che tutte le
frequenze sono contenute all'interno di un implulso. In generale, vale che
$$
F(u) = \int^{-\infty}_{+\infty} \delta(t - t_0) e^{-j 2\pi ut} dt = e^{-j 2 \pi u t_0}
$$
ciò significa che la trasformata della funzione delta di Dirac individua la
frequenza fondamentale multipla di $t_0$.

Inoltre, grazie alla relazione della trasformata inversa otteniamo che
$$
\delta(t) = \int^{-\infty}_{+\infty} e^{j2 \pi u t} du
$$

#### Segnale Monocromatico
Consideriamo il segnale monocromatico $f(t) = A cos(2 \pi u_0 t)$ e calcoliamone
la trasformata
$$
F(u) = \int^{-\infty}_{+\infty} A\; cos(2 \pi u_0 t) e^{-j2 \pi u t} dt =
A \left ( \delta(u - u_0) + \delta(u + u_0) \right )
$$
ciò significa che la trasformata sarà composta da due $delta$ di Dirac centrate
nei punti $u_0$ e $-u_0$. Questo è ragionevole poiché la trasformata è sempre
simmetrica rispetto all'asse $y$, per cui la funzione $delta$ individua la
frequenza $u_0$, che è effettivamente l'unica frequenza contenuta nella funzione
originale.

## Teorema della Convoluzione
Precedentemente abbiamo trattato la convoluzione come operazione di media mobile
nel discreto, ma è possibile definirla anche nel continuo. La convoluzione di
due funzioni $h$ e $f$ è così definita
$$
f(t) \star h(t) = \int^{\infty}_{-\infty} f(\tau) h(t - \tau) d\tau
$$

\begin{theorem}[Di Convoluzione]
La convoluzione di due funzioni $h$ e $f$ è pari al prodotto delle loro
rispettive trasformate $H$ e $F$, formalmente
$$
f(t) \star h(t) = F(u) \cdot H(u)
$$
\end{theorem}

La dimostrazione del teorema è banale, poiché basta applicare la definizione di
trasformata all'operazione di convoluzione. Calcoliamo innanzitutto la
trasformata di $h(t - \tau)$ per semplificare i calcoli successivamente
$$
\begin{split}
\mathscr{F}[h(t - \tau)]
& = \int h(t - \tau) e^{-j2 \pi u t} dt\\
& = \int h(v) e^{-j2 \pi u (v + \tau)} dv \;(v = t - \tau)\\
& = e^{-j2 \pi u \tau} \int h(v) e^{-j2 \pi v} dv\\
& = H(u) \cdot e^{-j2 \pi u \tau}
\end{split}
$$
passiamo ora a calcolare la trasformata della convoluzione, ottenendo quindi la
dimostrazione. Il passaggio principale consiste nel cambiare l'ordine degli
integrali (per linearità), sostituendo successivamente le varie definizioni che
compaiono
$$
\begin{split}
\mathscr{F}[f \star h]
& = \int \left ( \int f(\tau) h(t - \tau) d\tau \right ) e^{-j 2\pi u t} dt \\
& = \int f(\tau) \left ( \int h(t - \tau)  e^{-j 2\pi u t} dt\right ) d\tau \\
& = \int f(\tau) H(u) e^{-j 2\pi u \tau} d\tau \\
& = H(u) \int f(\tau) e^{-j 2\pi u \tau} d\tau \\
& = F(u) \cdot H(u) \quad \blacksquare
\end{split}
$$
da questo teorema risulta evidente il perché $h$ venga anche chiamato *filtro*.
Vale quindi che tutte le operazioni che abbiamo definito nel dominio dello
spazio per mezzo di un'operazione di convoluzione, possono essere fatte
semplicemente per mezzo di una moltiplicazione nel dominio delle frequenze.

Vale anche l'inverso, cioè $f(t) \cdot h(t) = F \star H$.

## Teorema del Campionamento
Per campionare un segnale possiamo utilizzare la proprietà vista in precedenza
della funzione $\delta$ di Dirac. L'idea è quella di definire una serie di
funzioni $\delta$ equispaziate di un certo $\Delta T$ (chiamato *periodo di
campionamento*). Si costruisce quindi il seguente *treno di impulsi*
$$
s(t) = \sum^{+\infty}_{n = -\infty} \delta(t - n \Delta T)
$$
la cui trasformata sarà
$$
S(u) = \frac{1}{\Delta T} \sum^{+\infty}_{n = -\infty} \delta(u -
\frac{n}{\Delta T})
$$
La trasformata è ancora un *treno di impulsi*, equispaziati di $\frac{n}{\Delta
T}$. Si noti che tanto più gli impulsi sono vicini nella funzione iniziale
(quindi valori $\Delta T$ piccoli che corrispondono ad una frequenza di
campionamento alta), tanto più gli impulsi nella trasformata saranno distanti.

Intuitivamente, quindi, se cerchiamo di avvicinare le varie delta tra loro nel
dominio spaziale (o temporale), le distanziamo nel dominio delle frequenze.
Questo è ragionevole perché la trasformata andrà a coprire frequenze più alte.

Dal punto di vista formale, il campionamento di un segnale continuo $f(t)$
consiste nel moltiplicare il treno di impulsi per tale segnale. Dal teorema di
campionamento, sappiamo che il prodotto di due funzioni nello spazio è la loro
convoluzione nelle frequenze, per cui il sengale campionato nello spazio delle
frequenze sarà cioè la convoluzione della trasformata di $f$ e della trasformata
del treno di impulsi $s$.
$$
\begin{split}
\tilde{F}(u) 
& = F(u) \star S(u)\\
& = \sum^{+\infty}_{n = -\infty} f(t) \cdot \delta(t - n \Delta T)\\
& = \int F(\tau) S(u - \tau) d\tau \\
& = \frac{1}{\Delta T} \int F(\tau) \sum_{n = -\infty}^{\infty} \delta \left ( u - \tau - \frac{n}{\Delta T} \right ) d\tau\\
& = \frac{1}{\Delta T} \sum_{n = -\infty}^{\infty} \int F(\tau) \delta \left ( u - \tau - \frac{n}{\Delta T} \right ) d\tau \quad (\delta \neq 0 \text{ solo quando } u - \tau - \frac{n}{\Delta T} = 0)\\
& = \frac{1}{\Delta T} \sum_{n = -\infty}^{\infty} F\left ( u - \frac{n}{\Delta T} \right ) d\tau\\
\end{split}
$$
questo risultato ci dice che la trasformata di Fourier del segnale
*digitalizzato* è una versione periodicizzata della trasformata di Fourier del
segnale *originale* di periodo $\frac{1}{\Delta T}$.

Quindi, per ricostruire il segnale originale, si potrebbe prendere solo il primo
periodo della funzione e poi andare ad applicare una trasformata inversa. Questo
però può essere fatto quando $\Delta T$ è sufficientemente piccolo da
distanziare bene le varie funzioni (si campiona a sufficienza). Se questo non
succede, le funzioni potrebbero essere troppo vicine e sovrapporsi tra di loro
(poiché la trasformata è una somma di tutte queste funzioni, per cui si
sovrappongono tra loro). Questo fenomeno viene detto *aliasing*.

Un teorema già citato in precedenza che ci permette di scegliere la frequenza di
campionamento con la garanzia che il segnale ricostruito sia indistinguibile da
quello originale è il teorema di campionamento Nyquist-Shannon. L'assunto di
questo teorema è che i segnali siano a banda limitata, cioè esista un limite
superiore di frequenze che non danno più contributi significativi all'intero
segnale. Questo è ragionevole dal punto di vista pratico, poiché oltre ad una
certa risoluzione, ad esempio, l'occhio non riesce a discernere alcuni
particolari. Sia quindi $\mu_{max}$ la frequenza massima (definita in base al
dominio), il teorema di Nyquist-Shannon ci dice che il segnale ricostruito è
instinguibile da quello originale se 
$$
\mu_{max} < \frac{1}{\Delta T} \quad e \quad \frac{1}{\Delta T} > 2\mu_{max}
$$
Quando le condizioni del teorema di campionamento non possono essere applicate,
cioè il segnale con cui si ha a che fare non è limitato in banda (non ha un
upper bound $\mu_{max}$), si può risolvere applicando un'operazione di
*anti-aliasing* a monte, in modo da eliminare tutte le frequenze al di sopra del
limite prefissato. Così facendo, si evita che durante il campionamento tali
frequenze compaiano e vadano ad interferire con le altre, creando di fatto
dell'aliasing. Nel caso delle immagini, applicare l'anti-aliasing corrisponde
semplicemente ad applicare un filtro passa basso, creando del *blurring*. Nelle
immagini, queste zone di alta frequenza sono rappresentate spesso da valori che
cambiano rapidamente (ad esempio in una scacchiera), per quello si parla di
smoothing.

Mettendo tutto insieme, per ricostruire il segnale originale, si applica la
trasformata inversa alla trasformata del segnale campionato, opportunamente
filtrata in una determinata finestra.
$$
f(t) = \mathscr{F}^{-1}(F(u)) = \mathscr{F}^{-1}(H(u) \cdot \tilde{F}(u)) 
$$

*(altri passaggi sono stati ommessi, per dettagli ulteriori, andare a pagina 47
delle slides)*

## Trasformata di Fourier (2 Dimensioni)
Fin'ora abbiamo trattato la versione ad una dimesnione della trasformata di
Fourier, ma quando parliamo di immagini parliamo invece di funzioni a due
variabili (come visto, $f(x, y)$ indica l'intensità di un singolo pixel).
Vale la pena introdurre la versione bidimensionale della trasformata di Fourier
$$
F(u, v) = \int_{\mathbb{R}}\int_{\mathbb{R}} f(t, z) e^{-j2\pi(ut + vz)} dt dz 
$$
Essa si ottiene semplicemente facendo prima la trasformata su una dimensione,
ottenendo una funzione intermedia e poi facendo la trasformata sulla restante
dimensione su questa funzione. La trasformata inversa è banale
$$
f(t, z) = \int_{\mathbb{R}}\int_{\mathbb{R}} f(t, z) e^{j2\pi(ut + vz)} du dv 
$$
Ovviamente, tutto ciò che è stato discusso in una dimensione vale anche per due
dimensioni, compreso il teorema del campionamento.

Per il processamento di immagini è necessaria la versione della trasformata 2D
nel continuo (DFT)
$$
F(u, v) = \sum_{x=0}^{M-1}\sum_{y=0}^{N-1} f(x, y) e^{-j2\pi (ux/M + vy/N)}
$$
sapendo ovviamente che $(x, y) \in M \times N$ è il dominio della funzione $f$
(dimensioni dell'immagine).

## Trasformata di Fourier e Immagini
Come detto, la Trasforamata ci permette di ottenere una rappresentazione in
termini di frequenze. Se noi applichiamo la DFT (2D) ad un'immagine, otterremo
la sua rapresentazion in termini di frequenze. Tipicamente se ne visualizza il
modulo in una scala logaritmica normalizzata in modo da avere l'origine al
centro. In questo modo, ovviamente si perde informazione di tipo spaziale, ma si
hanno importanti insights sulla composizione dell'immagine. Ad esempio, bruschi
cambiamenti (da bianco a nero) spesso corrispondono a linee di valori alti in
modulo che sono nella stessa direzione delle stesse nel dominio spaziale. Questo
perché la TF mantiene le informazioni di tipo *rotazionale*. D'altra parte,
valori che cambiano con meno frequenza saranno ovviamente rappresentati da
valori meno marcati, sempre sull'asse in cui queste variazioni occorrono.

*(si veda l'esempio sulle slides, pagina 81)*

Come detto, facendo il modulo si perde informazione di tipo spaziale, ma questa
informazione è invece contenuta nelle *fasi* delle varie sinusoidi. In altri
termini, la fase mantiene informazioni che rappresentano essenzialmente i
*bordi* contenuti nell'immagine.

## Elaborazione nel dominio delle frequenze
Alla base di ogni metodo di elaborazione abbiamo sempre l'operazione di
convoluzione già vista in precedenza. 
$$
f(x, y) \star h(x, y) = \sum_{m=0}^{M-1} \sum_{n=0}^{N-1} f(m, n)h(x - m, y - n)
$$
In frequenza, possiamo sfruttare il teorema della convoluzione e fare questo
tipo di processing semplicemente per mezzo di una moltiplicazione.
Ovviamente, quando si vanno a fare le trasformate, spesso si ottengono due
matrici di dimensioni differenti. Spesso, infatti, il kernel (o filtro) ha
dimensioni molto più ridotte rispetto all'immagine. Questo si risolve facendo
*0-padding* sulla matrice della trasformata del kernel in modo che le dimensioni
siano le stesse.

Quando facciamo le trasformate, dobbiamo vedere le immagini come dei segnali
periodici, cioè che si ripetono all'infinito su tutte le dimensioni $x$ e $y$.
Questa periodicità può causare degli artefatti ai bordi delle immagini sotto
opportune condizioni, chiamato problema della *circular convolution*. Per
mitigare questo fenomeno, si fa 0 padding in entrambe le immagini (kernel e
immagine in input) in modo tale rendere le immagini entrambe di dimensioni $P
\times Q$, dove
$$
\begin{split}
P &= A + C - 1\\
Q &= B + D - 1\\
\end{split}
$$
in cui:

* $A \times B$ sono le dimensioni dell'immagine;
* $C \times D$ sono le dimensioni del kernel.
