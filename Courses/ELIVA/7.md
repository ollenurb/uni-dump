# Image Restoration
L'image restoration ha come obiettivo il *miglioramento* dell'immagine, ma a
differenza dell'*enhancement* (che è un processo soggettivo), si tratta invece
di un processo **oggettivo**. Il *modus operandi* consiste nel modellare il
*difetto* dell'immagine, per poi poterlo riparare. Si utilizzano poi delle
funzioni per misurare la *performance* della tecnica di restoration utilizzata,
in modo da raggiungere un risultato ottimale. Così come l'enhancement, possiamo
effetture la restoration sia nel dominio delle frequenze (es. *blur removal*),
che nel dominio spaziale (es. *additive noise reduction*).

> Tipicamente quando ci sono problemi nell'immagine che hanno una località
> spaziale (che sono più prominenti in alcune zone specifiche dell'immagine) si
> preferisce un processing a livello spaziale. D'altra parte, se il problema è
> distribuito su tutta l'immagine, è preferibile un processing in frequenza
> (soprattutto se si tratta di un pattern periodico).

Ci sono due grandi problemi legati alla restoration:

* *Denoising*: in cui vengono utilizzati modelli che approssimano il rumore
  dell'immagine e un successivo filtering dello stesso. Di solito viene
  approcciato nel dominio spaziale;
* *Inversion*: consistono nel modellare la funzione degradante per ottenerne
  l'inversa, in modo tale che da invertire il processo degradante. Di solito
  viene approcciato nel dominio delle frequenze.
 
Questi due problemi non sono isolati tra loro ma bensì sono legati in diversi
modi che saranno chiariti più avanti nel capitolo.

Prima di iniziare il capitolo, è necesario però introdurre il modello matematico
che descrive il processo di degrado e restauro a cui si farà riferimento per il
resto del capitolo. Si suppone di aver un'immagine ideale $f(x, y)$ a cui viene
applicata una funzione di degrado $H$, utilizzata per modellare difetti di
*acquisizione* (es. movimento del sensore, blurring atmosferico), e
successivamente ne viene aggiunto un certo rumore, modellato dalla funzione
$\eta(x, y)$ (es. rumore del sensore). L'immagine degradata da queste due
operazioni è $g(x, y)$. A questo punto, si applicano i filtri di restoration che
sfrutteranno delle conoscenze specifiche su $H$ e $\eta$, e sarà tanto più
efficace tanto più precise le approssimazioni delle funzioni degradanti. Il
processo di restoration produrrà un'immagine $\hat{f}(x, y)$ che sarà una stima
dell'immagine originle $f(x, y)$ (*ground-truth*).

## Rumore statistico additivo
Ci concentreremo su una classe specifica di problemi, caratterizzata di funzioni
di degrado *lineari* e *position-invariant* e rumore *additivo*. La funzione di
degrato è deterministica, poiché spesso viene modellata sulla base di
osservazioni o specifiche del sensore di acquisizione. Il rumore additivo,
invece, è determinato dall'ambiente per cui è un qualcosa di totalmente casuale
ed è quindi un modello statistico.

Dal punto di vista spaziale, possiamo rappresentare l'intero processo di degrado
come:
$$
g(u, v) = h(u, v) \star f(u, v) + \eta(u, v)
$$
Sfruttando il teorema di Convoluzione possiamo ottenere la rappresentazione
equivalente nel dominio di Fourier:
$$
G(u, v) = H(u, v)F(u, v) + N(u, v)
$$

Il rumore $\eta$ è affetto da diversi fattori, che possono essere anche
introdotti dagli strumenti di cattura. Ogni sensore, infatti, ha una propria
*cifra di rumore*, tant'è che i produttori di sensori provvedono a fornire una
cosiddetta curva che indica il *signal-to-noise* ratio in funzione dell'apertura
ISO. Per ridurre questo rumore, infatti, spesso si vanno a fare delle medie tra
diverse misurazioni per avere delle stime più precise. Anche il rumore si può
analizzare in frequenza. Degno di nota è il cosiddetto *white-noise*, un rumore
uniforme ovunque che viene introdotto impostando a 0 i pixel in modo casuale. La
componente spettrale di questo rumore sarà una funzione costante, cioè contiene
tutte le frequenze di altezza $sigma^2$. In generale, inoltre, il rumore che
considereremo è invariante per posizione.

Il rumore $\eta(x, y)$ viene costruito a partire da una densità di probabilità
$f_{\eta}(z)$ che indica la probabilià che nella matrice $\eta$ ci sia un certo
valore di intensità.
Possiamo modellare questa distribuzione con diverse distribuzioni note, ad
esempio:

* **Gaussiana**: $p(z) = \frac{1}{\sqrt{2 \pi \sigma}} e^{-(z - \bar{z})^2/
  2\sigma^2}$, centrata nel valor medio $\bar{z}$ e avrà tanto più rumore tanto
  più $\sigma$ sarà grande;
* **Uniforme**;
* **Rayleigh**;
* **Esponenziale**;
* **Impulso**.

Per capire sperimentalmente se nell'immagine c'è del rumore è confrontare la
stima della proabilità dell'intensità dei pixel. L'istogramma è proprio una
distribuzione dei livelli di intensità dell'immagine e può fornire
un'approssimazione iniziale della distribuzione ricercata. Ovviamente questa è
un'approssimazione molto grezza poichè modella le varie intensità in modo
indipendente, nonostante queste siano dipendenti dalla loro posizione spaziale
nell'immagine [^fnote2]. Ottenere un modello statistico che tenga conto anche
della correlazione tra i pixel è molto difficile, ed esula dagli scopi di questo
corso.

[^fnote2]: Per convincersene, è sufficiente prendere l'istogramma di un'immagine
  e utilizzarlo per generare una nuova immagine, campionando semplicemente i
  valori dei pixel dall'istogramma in modo proporzionale ad esso. Quello che si
  otterrebbe non è un'immagine simile a quella ottenuta ma semplice rumore,
  proprio perché la distribuzione non tiene conto delle correlazioni spaziali
  tra pixel.

Abbandonando quindi l'idea di modellare statisticamente l'intera immagine, ci si
può focalizzare invece sulla modellazione statistica del rumore. Esso è appunto
un processo indipendente dal punto di vista statistico, per cui l'istogramma
potrebbe rappresentare un'ottima approssimazione della distribuzione. 

Se si fa appunto l'assuzione che il rumore sia uniforme e spazio invariante,
focalizzandosi su determinate porzioni dell'immagine e calcolandone
l'istogramma, saranno evidenti la dispersione rispetto al valore medio (il
valore reale dell'immagine senza rumore) introdotta dal rumore. Difatti, se ci
si focalizza su zone sufficientemente uniformi dell'immagine, l'istogramma
assumerebbe proprio la forma di una distribuzione simile a quella del rumore
stesso, centrata sul valore della porzione dell'immagine (il valore di pixel che
è uguale per tutti i pixel della porzione siccome è uniforme).

Se supponiamo di non conoscere la distribuzione del rumore, l'idea è quindi
quella di prendere più porzioni uniformi dell'immagine e calcolarne
l'istogramma. Se la distribuzione è simile per tutti allora si può dedurre che
il rumore è spazio invariante, additivo e bianco (scorrelato da punto a punto).
Quindi la forma dell'istogramma rappresenta un modo di capire qual'è la densità
di probabilità del rumore e tramite un processo di fitting è anche possibile
andare a stimare quali siano i parametri di questa distribuzione.

Per rimuovere il rumore whitenoise si va a fare una media delle misurazioni in
modo da abbassare la varianza $\sigma^2$. Tale operazione corrisponde di fatto a
fare un filtro passa-basso nel dominio della frequenza. Se si immagina appunto
il rumore presente nell'immagine, nel dominio di Fuorier comparirebbe come una
funzione costante alta $\sigma^2$. L'applicazione di un filtro passa basso
permette di rimuvere tutto quel rumore dopo la soglia del filtro, che
tipicamente non contiene troppe informazioni riguardo l'immagine (frequenze
alte), siccome tipicamente le immagini hanno un'alta concetrazione dell'energia
nelle frequenze basse.

Un'altra tipologia di rumore è il rumore periodico, che a questo punto comparirà
nella rappresentazione spaziale come una delta centrata nella frequenza dello
stesso. Per rimuovere questo rumore si può utilizzare un Notch filter, visto in
precedenza.

Possiamo concludere che il rumore possiamo processarlo sia in frequenza che
nello spazio. Se il rumore è periodico si preferisce processarlo in frequenza,
se invece si tratta di whitenoise, allora si preferisce il processing nello
spazio.

### Filtri lineari
Come già accennato, i filtri spaziali utilizzati sono principalmente delle medie
(dove $S_{xy}$ è l'intorno del pixel $(x, y)$ di dimensioni $m \times n$):

* **Aritmetica**: in cui il rumore è ridotto dal blurring;
  $$
  \frac{1}{nm}\sum_{(s, t) \in S_{xy}} g(s, t)
  $$
* **Geometrica**: i dettagli sono maggiormente preservati;
  $$
  \hat{f}(x, y) = \left[ \prod_{(s, t) \in S_{xy}} g(s, t) \right
  ]^{\frac{1}{nm}}
  $$ 
* **Armonica**: buoni per rumori *"salt"* e Gaussiano;
  $$
  \hat{f}(x, y) =\frac{nm}{\sum_{(s, t) \in S_{xy}} 1/g(s, t)}
  $$
* **Contrarmonico**: generalizzazione delle medie armoniche e aritmetiche.
  $$
  \hat{f}(x, y) = \frac{\sum_{(s, t) \in S_{xy}} g(s,
  t)^{Q+1}}{\sum_{(s, t) \in S_{xy}} g(s, t)^{Q}}
  $$
    * Con $Q>0$ buono per la rimozione del rumore *"pepper"*;
    * Con $Q<0$ buono per la rimozione del rumore *"salt"*;
    * Con $Q=0$ corrisponde alla media *aritmetica*;
    * Con $Q=-1$ corrisponde alla media *armonica*.

È utile osservare che applicare questi smoothing non elimina completamente il
rumore. Inoltre, anche la qualità dell'immagine viene intaccata un minimo.
Bisogna quindi trovare il compromesso tra i due.

### Filtri non lineari
Possiamo usare anche filtri non lineari per rimuovere il rumore, come diversi
filtri basati su statistiche ordinate:

* **Mediana**: rimuove rumore a impulso;
  $$
  \hat{f}(x, y) = \text{median}_{(s,t) \in S_{xy}} g(s, t)
  $$
* **Massimo**: riduce rumore pepe;
  $$
  \hat{f}(x, y) = \max_{(s,t) \in S_{xy}} g(s, t)
  $$
* **Minimo**: riduce rumore sale;
  $$
  \hat{f}(x, y) = \min_{(s,t) \in S_{xy}} g(s, t)
  $$
* **Punto medio**: 
  $$
  \hat{f}(x, y) = \left [ \max_{(s,t) \in S_{xy}} g(s, t) \min_{(s,t) \in
  S_{xy}} g(s, t) \right ]/2
  $$
* **Alpha Trimmed**: rimuove prima del calcolo della media, sia i $d/2$ valori
  più piccoli che più grandi. Lavora bene con rumore sale-pepe e Gaussiano
  mischiati insieme.
  $$
  \hat{f}(x, y) = \frac{1}{mn-d} \sum_{(s,t) \in S_{xy}} g'(s, t)
  $$

### Filtri adattivi
Sono filtri che adattano il loro comportamento al contenuto di una finestra
locale $m \times n$. Questi filtri vengono applicati solamente a zone in cui non
c'è molto rumore per evitare di incentivarlo. Una possibilità è quella di
raccogliere delle statistiche locali di ogni finestra $S_{xy}$ che si va a
processare. Un esempio visto riguarda appunto il calcolo della *media* (che
rappresenta la *luminosità* media) e la *varianza* (che rappresenta il
*contrasto*) locali.
L'idea è che in punti in cui la varianza è molto alta, è molto probabile che ci
si trovi in prossimità di un bordo, per cui rappresenta un dettaglio che
auspicabilmente non si deve processare per evitare di danneggiarlo.
D'altra parte, se la varianza è bassa o è molto simile ad una varianza
sperimentale (ad esempio data dal difetto del sensore di acquisizione), allora
si è in prossimità di rumore, per cui si va a processare con un filtro.
Un filtro adattivo di questo tipo è il seguente:
$$
\hat{f}(x, y) = g(x, y) - \frac{\sigma_{\eta}^2}{\sigma_L^2}[g(x, y) - m_L]
$$
in cui:

* $\sigma^2_{\eta}$ è la varianza del rumore del sensore, oppure di un rumore
  ottenuto sperimentalmente a partire da un dataset di immagini;
* $\sigma^2_L$ è la varianza locale;
* $m_L$ è la media locale.

Dalla formula, è evidente che il rapporto tra $\sigma^2_{\eta}$ e $\sigma_L^2$
sia fondamentale, poiché determina il comportamento del filtro. Nello specifico,
possiamo distinguere i diversi casi:

* $\sigma^2_{\eta}= 0$ allora non c'è rumore, per cui non si processa e si
  ritorna $g(x, y)$;
* Se $\sigma^2_{L} = \sigma^2_{\eta}$ allora $\hat{f}(x, y) =
  \text{mean}_{S_{xy}} g(x,y)$. Si è in prossimità di un punto che ha le stesse
  proprietà globali dell'immagine, per cui vogliamo processarla;
* Se $\sigma^2_{L} >> \sigma^2_{\eta}$ allora $\hat{f}(x, y) \approx g(x, y)$.
  Si è in prossimità di un punto in cui ci sono bordi o dettagli importanti che
  non devono essere processati principalmente per due motivi: si rovinerebbero i
  dettagli e comunque il rumore sarebbe meno visibile poiché i dettagli lo
  *"coprirebbero"*.

Un'altra possibilità per creare filtri adattivi è quella di variare i parametri
dei filtri in base all'immagine, al posto di decidere se applicare o meno il
filtering in base ad essa.
Un tipo di questo filtro è l'*adaptive median filter*, in cui viene cambiato
l'unico parametro del filtro mediano: le dimensioni del filtro stesso. Infatti,
l'idea alla base di questo filtro è quella di *ridurre* le dimensioni in
prossimità di punti in cui la varianza è alta e di *accrescerle* in punti in cui
è bassa. Vale la pena introdurre le notazioni che verranno utilizzate
nell'algoritmo in seguito:

* $S_{xy}$ è l'area centrata nel punto $z_{xy}$
* $z_{min}$ è l'intensità minima nell'area considerata;
* $z_{max}$ è l'intensità massima nell'area considerata;
* $z_{med}$ è l'intensità mediana nell'area considerata;
* $z_{xy}$ è l'intensità del pixel nella posizione $(x, y)$;
* $S_{max}$ è la grandezza massima dell'area consentita.

\begin{algorithm}
\caption{Adaptive Median Filter}
\begin{algorithmic}[1]
\State $A1 \gets z_{med} - z_{min}$
\State $A2 \gets z_{med} - z_{max}$
\If{A1 > 0 and A2 < 0} \Comment{Apply the median filter}
    \State $B1 \gets z_{xy} - z_{min}$
    \State $B2 \gets z_{xy} - z_{max}$
    \If{B1 > 0 and B2 < 0}
        \State output $z_{xy}$
    \Else
        \State output $z_{med}$
    \EndIf
\Else
    \State increase $S_{xy}$
\EndIf 
\If{$S_{xy} \leq S_{max}$}
    \State goto start (recomputing min, max and med)
\Else
    \State output $z_{med}$
\EndIf
\end{algorithmic}
\end{algorithm}

## Rumore additivo periodico
Come già accennato in precedenza, il rumore periodico viene invece processato
nello spazio delle frequenza. L'idea principale è quella di applicare dei filtri
bandreject o Notch per rimuovere le stesse dall'immagine.

Come visto, la rimozione di queste frequenze viene spesso fatta per mezzo di
filtri che hanno un profilo Gaussiano. Questo però ci crea dei problemi siccome
un filtro moltro stretto nel dominio delle frequenze (con $\sigma^2$ piccolo)
corrisponderà ad una Gaussiana molto larga nel dominio dello spazio (con
$1/\sigma^2$).
Per risolvere il problema l'idea è quella di isolare le componenti da rimuovere,
moltiplicarle per un determinato peso e sottrarle dall'immagine rumorosa. Questo
approccio è implementato dall'*optimal Notch filtering*.
Anziché rimuovere direttamente le componenti di frequenza che causano rumore,
l'approccio consiste nell'estrarre le componenti tramite un filtro Notch pass,
per poi ottenere il rumore facendone l'antitrasformata.
$$
\eta(x, y) = \mathscr{F}^{-1}[H_{np}(u, v)G(u, v)]
$$
A questo punto, sottraiamo il rumore ottenuto pesato per un'opportuna funzione
che minimizza gli effetti dei componenti che non sono presenti in $\eta(x, y)$.
$$
\hat{f}(x, y) = g(x, y) - w(x, y)\eta(x, y)
$$
dove $w(x, y)$ è la funzione di *"pesatura"*, che in un certo senso rende
adattivo il filtro, poiché decide quando e di quanto attivare il filtro Notch.
Il criterio per decidere se applicare o meno il filtro è quello di minimizzare
la varianza all'interno di un intorno $(2a +1) \times (2b + 1)$. Questo è
motivato dal fatto che le immagini in generale hanno una varianza locale bassa
per ogni $(x, y)$. Formalmente:
$$
w(x, y) = \arg \min_{(x, y) \in S_{xy}}\sigma^2_L(x, y)
$$


