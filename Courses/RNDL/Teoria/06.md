# Self Organizing Maps
Le self organizing maps sono delle reti che il cui setting di apprendimento e'
*non supervisionato*: imparano a classificare un set di input associando ogni
input ad un neurone simile. In questo senso, scoprono delle regolarita'
nell'insieme di input.

> *Le SOM imparano a produrre una rappresentazione (tipicamente) bidimensionale
> dei dati in input, preservandone l'ordine topologico.*

Preservare l'ordine topologico significa che input simili vengono mappati in
neuroni che sono vicini tra did loro all'iterno della griglia.

In generale sono delle griglie bidimensionali di neuroni. Le griglie sono
singole, per cui non sono delle reti neurali a multilivello. I neuroni sulla
griglia sono relazionati tra loro solamente per mezzo di una relazione di
*vicinanza*, per cui non esiste nessuna connessione (mediata da pesi) tra i
neuroni sulla griglia.

> *E' possibile anche utilizzare una topologia *lineare* al posto di una
> topologia a *griglia* (o esagonale)*

Ogni neurone e' connesso mediante un insieme di pesi ad un vettore di input. Per
cui, ogni neurone avra' associato:

* Un vettore di pesi (un peso per ogni feature), detto anche *prototype vector*
* Una posizione (coordinata che non cambia mai) all'interno della griglia

**Best Matching Unit** (BMU): E' il neurone che si attiva di piu' in tutta la
rete quando gli viene presentato un esempio.

La BMU del neurone *i-esimo* viene calcolata in termini della distanza Euclidea
tra il vettore di pesi $w_i$ e il vettore di input $x$. La BMU e' quella con
attivazione minima:

$$
BMU(x) = \arg \min_i \|x - w_i\|
$$

Questo perche' c'e' una relazione precisa tra il prodotto scalare e la norma:

> *Il prodotto scalare piu' grande e' quello la cui distanza e' minima.*

In questo senso determiniamo il neurone che si attiva di piu' solamente
considerandone la distanza, senza dover calcolare esplicitamente l'attivazione
(per mezzo del prodotto scalare). 

L'apprendimento di una rete SOM si fonda quindi su due principi:

* Principio di **competizione**: ogni neurone va a "*competere*" con tutti gli
  altri per potersi attivare. I pesi del neurone che vince la competizione (e
  che quindi si attiva),  vengono modificati in modo da aumentare la
  probabilita' che sia di nuovo in grado di attivarsi per istanze di input
  simili (o per la stessa istanza di input).
* Principio di **cooperazione**: il cambiamento dei pesi non riguarda solo le
  BMU, ma anche i neuroni vicini ad essa

Ovviamente questi due principi vengono tenuti in conto contemporaneamente dalla
regola di update dei pesi.

> *Le BMU che si attivano vicine tra di loro rappresentano una determinata
> classe.* 

La regola di update dei pesi e' la seguente:

$$
w_i(n + 1) = w_i(n) + \eta(n) (x - w_i(n))
$$

In questo senso, i pesi della BMU vengono *trascinati* verso l'esempio di input
(ovviamente) in modo proporzionale al learning rate $\eta$. Ovviamente, dobbiamo
anche introdurre il concetto di cooperazione. Idealmente, ogni volta che viene
presentato uno stimolo (esempio) alla mappa, l'update rule viene applicata alla
BMU e a tutti i neuroni circostanti ad essa. La relazione di *vicinanza* dipende
direttamente dalla distanza del segnale rispetto alla BMU. Piu' formalmente la
*vicinanza* tra due unita' $j$ e $i$ e' descritta da una Gaussiana:

$$
h_{j, i} (n) = exp(-\frac{d_{j,i}^2}{2 \sigma(n)^2})
$$

Tenendo in conto questa relazione, l'update rule **per ogni neurone** $j$ della
mappa e'

$$
w_j(n + 1) = w_j(n) + \eta(n) \cdot h_{j, i}(n) \cdot (x - w_j(n))
$$

Nella formula, $i$ e' l'indice del neurone BMU dell'iterazione attuale, per cui
e' evidente come i neuroni che sono piu' coinvolti dal cambiamento del peso
siano quelli che hanno $h_{j,i}$ grande, cioe' tali per cui la distanza tra loro
e al BMU e' piccola (in questo caso, il massimo sara' quando $i$ = $j$, cioe'
quando il neurone $j$ e' la BMU che ha distanza tra se stessa $=0$).

> *Il coinvolgimento decresce all'aumentare della distanza, per cui i pesi
> saranno cambiati sempre meno per le unita' piu' lontane.*

Cosi' come il learning rate, anche l'ampiezza $\sigma$ della Gaussiana decresce
con l'aumentare il passare del tempo, per cui segue una decrescita esponenziale,
data dalla seguente legge

$$
\sigma(n) = \sigma_0 exp\left( -\frac{n}{\tau} \right) 
$$

per cui sempre meno neuroni verranno considerati dalla regola di update dei
pesi. Tipicamente, l'apprendimento di una self organizing map e' divisa in due
fasi: 

1. In questa prima fase, la mappa si macro-organizza, cioe' il *"vicinato"*
   delle BMU ha dei valori tali per cui ogni cambiamento di peso va a
   influenzare in modo molto forte gli altri pesi della mappa. In questa fase il
   learning rate e' abbastanza alto
2. In questa fase successiva e' detta di convergenza, poiche' il *"vicinato"* si
   e' ristretto cosi' tanto da essere in grado di influenzare solo piu' una
   unita' alla volta

### Errore

Ci due misure per quantificare l'errore delle SOM:

* **Errore di quantizzazione**: Misura l'errore medio tra ogni stimolo e il
  neurone che lo rappresenta meglio (la BMU). In generale, misura quanto bene la
  mappa rappresenta bene i dati.

$$
QE = \frac{\sum^L_{l=1} \| x_l -w_{i(x_l)}\|}{L}
$$

* **Errore Topologico**: La topologia e' preservata se punti vicini nello spazio
  di input sono vicini anche nel reticolo di output e viceversa. L'errore
  topologico misura 

$$
TE = \frac{1}{L} \sum^L_{l=1} u(x_l)
$$

(dove $u(x)$ e' $=1$ se le prime due $BMU$ sono adiacenti tra loro nello spazio
di output, $0$ altrimenti)

### Casi d'uso e applicazioni

Le Self Organizing Maps vengono utilizzate principalmente per i seguenti task:

* Clusterizzare dati
* Visualizzare dati con dimensionalita' molto alta
* Comprimere dataset molto grossi -> Creando una SOM a partire da un grosso
  dataset, e' possibile prendere tutte le zone adicenti delle SOM e renderle una
  singola istanza.

Applicazioni delle SOM:

* Riconoscere fonemi
* Descrivere modelli cognitivi
