# Recurrent Neural Networks
Le reti ricorrenti sono nate per modellare task che hanno a che fare con le
*sequenze*. Alcuni esempi possono essere:

* Speech Recognition: converti una sequenza di frequenze in una sequenza di
  parole
* Sentiment Classification: converti una sequenza di parole nel sentimento che
  viene espresso (rabbia/gioia/ecc..)
* Multi-Omics Sequence Analysis: converti una sequenza di DNA/RNA nella sua
  corrispondente proteina

Altri task inerenti alla linguistica sono:

* Predirre se un determinato *verbo* e' plurale o singolare
* Predirre la prossima parola
* Determinare la correttezza grammaticale di una frase

Per spiegare meglio questo tipo di reti, considereremo un task specifico:
*determinare quali parole di una frase in input sono un nome proprio*.

Esempio:

* Input: $\mathbf{x}=$*"**Harry Potter** and **Hermione Granger** invented a new
  spell"*
* Output: $\mathbf{y}= (1, 1, 0, 1, 1, 0, 0, 0, 0)$

In cui nel vettore di output ogni valore $\mathbf{y}^{(t)}$ indica che la parola
$t$-esima e' o meno un nome proprio. (*la notazione e' differente rispetto a
quella vista fino ad ora per altre reti*)
Con $Tx^{(i)}$ e' la lunghezza della sequenza in input $i$-esima
$\mathbf{x}^{(i)}$.

> *Si noti come in questi modelli la lunghezza $Tx^{(i)}$ puo' sempre variare a
> seconda dell'esempio $i$, diversamente da qualsiasi altra rete vista fin'ora
> dove la lunghezza (numero di features) era fissa*

Le frasi sono codificate con una rappresentazione *one-hot*, cioe' vengono
rappresentate come dei vettori che hanno tante componenti quante sono le parole
del vocabolario, in cui sono le posizioni corrispondenti alle parole che sono
presenti sono uguali a $1$.

Per motivare le reti ricorrenti, proviamo a porci la domanda se sia possibile in
primo luogo risolvere questo problema con una rete Feed-Forward normale.
Effettivamente, se abbiamo una frase codificata in one-hot encoding, abbiamo
stabilito un numero di features fisso, per cui potremmo utilizzare
effettivamente una di queste reti.
Questo approccio presenta pero' tre problemi principali:

1. Sia gli input che gli output possono avere lunghezze differenti in diversi
   esempi
2. Non riesce a tenere conto delle features apprese in diverse posizioni del
   testo
3. Non puo' tenere conto del *contesto* delle singole parole all'interno delle
   frasi

Le reti ricorrenti invece riescono a tenere conto degli elementi precedenti
della sequenza ad ogni elemento che processano.
Una rete ricorrente non e' nient'altro che l'applicazione ricorsiva della stessa
rete. Intuitivamente, possiamo vedere la sua versione *unrolled* come
l'applicazione di una serie di multi-layer perceptrons, che prendono in input
anche lo stato risultante dai MLP precedenti.

Se $g^{(t)}(x^{(t-1)}, x^{(t-1)}, \dots, x^{(1)})$ e' la funzione che calcola
l'intera rete, possiamo rappresentare la stessa funzione con la stessa formula
di ricorrenza $f(h^{(t-1)}, x^{(t)}, \theta)$.

Guardare una rete ricorrente in questi termini introduce diversi vantaggi:

1. Il modello appreso avra' sempre la stessa grandezza di input (una sola parola
   della sequenza nel caso del text processing) indipendentemente dalla
   lunghezza della sequenza.
2. Dal momento che la funzione di transizione $f$ ha sempre gli stessi parametri
   per ogni timestep, e' possibile apprendere un singolo modello $f$ per tutti i
   timesteps $t$ al posto di imparare un modello $g$ per ogni possibile
   timestep.

Se noi presentiamo un input alla rete, essa funziona nel modo seguente:

* Calcola l'attivazione della rete con $\mathbf{x}^{(1)}$, producendo l'output
  corrispondente $\mathbf{\hat{y}}^{(1)}$ 
* Calcola l'attivazione di un MLP con $\mathbf{x}^{(2)}$, ma tenendo conto
  dell'attivazione del layer *hidden* $h^{(1)}$ del passo precedente, producendo
  l'output corrispondente $\mathbf{\hat{y}}^{(2)}$ 

E cosi' via fino alla fine della sequenza.

Piu' formalmente, possiamo calcolare i vari componenti come:

$$
\begin{split}
h^{(t)} &= tanh(\underbrace{W \cdot h^{(t-1)}}_{\text{H.L. precedente}} + \underbrace{U \cdot \mathbf{x}^{(t)} + \mathbf{b}}_{\text{H.L. attuale}})\\
\mathbf{o}^{(t)} &= softmax(V \cdot h^{(t)} + \mathbf{c})
\end{split}
$$

in cui:

* $h^{(0)} = \mathbf{0}$ oppure e' inizializzato con un vettore *casuale*
* $W$ sono i pesi che connettono le unita' hidden con le unita' hidden del passo
  predente (*hidden-to-hidden*)
* $U$ sono i pesi che connettono le unita' di input input alle unita' hidden
  (*input-to-hidden*)
* $V$ sono i pesi che connettono le unita' di hidden alle unita' output
  (*hidden-to-output*)
* $b$ e $c$ sono i bias

>*I pesi sono sempre gli stessi, condivisi da ogni passo.*

L'apprendimento di queste reti e' *supervisionato*, e si allenano mediante
*backpropagation*. L'unica differenza e' che l'algoritmo e' detto
*Backpropagation Though Time* (BPTT). L'idea e' sempre quella della
backpropagation:

* Data una singola frase di input, calcola l'attivazione di tutte la rete (tutti
  i timestep che consentono di arrivare alla fine della frase)
* Calcola la discrepanza tra l'output restituito ad ogni timestep e l'output
  desiderato a quel determinato timestep
* Viene calcolato l'errore complessivo della rete come la somma delle
  discrepanze calcolate ad ogni timestep
* Si propaga il gradiente dell'errore all'indietro

Possiamo definire la funzione di *loss* sul singolo passo nel modo seguente (sia
$\mathbf{y}$ il *true target*)

$$
\mathscr{L}^{(t)}= y^{(t)} - h^{(t)} 
$$

possiamo quindi calcolare la loss totale come la somma di tutte le loss ai
singoli timestep

$$
\mathscr{L}_{tot}= \sum^{Tx}_{t=1} \mathscr{L}^{(t)}
$$

quindi l'update dei pesi del gradient descent dovra' tenere conto della loss
totale

$$
\Delta w_{ij} = \sum^{Tx}_{t=1} \frac{\partial  \mathscr{L}^{(t)}}{\partial w_{ij}}
$$

Per cui ogni peso terra' conto della loss che e' stata prodotta anche ai passi
precedenti (questo e' ragionevole siccome i pesi sono condivisi e vanno a
influenzare TUTTI i passaggi).

>*La backpropagation dovra' essere fatta sia sul flusso computazionale del
>modello, che su quello del **tempo***.

Il problema e' che l'algoritmo di apprendimento BTT non e' un algoritmo stabile
e presenta un problema principale: Piu' aumentano i passaggi, piu' c'e' la
possibilita' di un *dissoluzione* o *esplosione* numerica del gradiente. Questo
perche' piu' sono i passaggi, piu' ci sono moltiplicazioni di gradienti, per cui
e' molto probabile che il gradiente svanisca e verso gli step iniziali i
cambiamenti sarebbero praticamente nulli.

In questo senso, l'algoritmo cerca di fare degli update considerando l'errore
generato da timestep molto indietro nel tempo. E' come se si cercasse di
spiegare un comportamento successo attualmente guardando ad anni di distanza. In
altri termini, e' difficile che l'errore commesso ai passi precedenti abbia
un'influenza significativa sull'errore attuale.

Ci sono diversi modi per risolvere questi problemi:

1. Usare una versione dell'algoritmo di apprendimento chiamato *truncated BPTT*,
   in cui si vanno a considerare solo delle finestre temporali (in cui possono
   essere sovrapposte)
2. Fare gradient clipping (nel caso dell'esplosione)
 
>*Le LSTM nascono principalmente per risolvere questi problemi tecnici nelle reti
>ricorrenti*

Siccome le reti ricorrenti possono avere diverse dimensioni in input e output,
possiamo categorizzarle in base allo schema di mapping:

* **One to Many**: dato un singolo *input* ritorna una sequenza in *output* (es.
  image captioning)
* **Many to One**: data una sequenza in *input*, ritorna un singolo *output*
  (es. sentiment analysis)
* **Many to Many**: data una *sequenza* di input, ritorna una sequenza in
  *output* (es. machine translation)

### Generazione di Sequenze

Le reti ricorrenti possono essere utilizzate anche per *generare* le sequenze.
Solitamente vengono generate in maniera *autoregressiva* per cui questo tipo di
modelli e' detto *autoregressive decoder*.
Proprio per la loro natura autoregressiva, questo tipo di architettura deve
avere un criterio di STOP, di solito codificato all'interno di un token
particolare.

Sempre nell'ambito di generazione di sequenze possiamo parlare di un algoritmo
particolare chiamato **Beam Search** che tiene conto solo delle parole scelte
allo step precedente.

Diversi score possono essere utilizzati per valutare le sequenze generate:

* Accuracy
* MSE
* ROUGE (Recall-Oriented Understudy for Gisting Evaluation)
* BLEU (Bilingual Evaluation Study)
* Perplexity
* Factual Score (deve essere definito in base al dominio di riferimento)
