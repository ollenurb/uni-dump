# Hopfield Networks

Particolarmente apprezzate da scienziati cognitivi e fisici, le reti di Hopfield
fanno parte del repertorio che ogni DL engineer deve sapere.
Sono reti che risolvono task di tipo *pattern completion* (es. Data una porzione
di frase, la rete riesce a completarla). Hanno un insieme di memorie
fondamentali *"cablate"* all'interno della rete. Data una versione corrotta di
una memoria fondamentale, la rete puo' ricostruirla gradualmente.

> *Le reti di Hopfield possono essere usate per modellizzare un gran numero di
> fenomeni cognitivi degli esseri umani tra le quali memoria, lessico, afasia,
> abilita' di riconoscere facce, ecc..*

Una rete di Hopfield e' un insieme di **neuroni** completamente connessi tra di
loro, per cui ogni neurone e' connesso a tutti gli altri neuroni eccetto se
stesso.

> *Come regola generale, vale anche che $w_{i,j} = w_{j,i}$ (i pesi sono
> simmetrici)*

Ogni neurone puo' avere solo due attivazioni possibili: 1 o -1. Cosi' come ogni
altra rete vista fin'ora, l'attivazione di un neurone e' calcolabile applicando
la funzione di attivazione alla somma pesata di tutti gli altri neuroni della
rete connessi ad esso.
La funzione di attivazione tiene conto anche dell'attivazione al passo
precedente. Piu' formalmente, sia $v_j(n)$ il campo di output del neurone $j$
all'iterazine $n$:

$$
v_j(n) = \sum_{i=0}^N w_{ij} \; \cdot \; y_i(n) 
$$

Allora l'output del neurone $j$ all'iterazione $n$ e' calcolabile nel modo
seguente:

$$
\varphi(v_j)(n) =
\begin{cases}
1 & \; \text{if} \; v_j(n) > 0\\
-1 & \; \text{if} \; v_j(n) < 0\\
\varphi(v_j)(n-1) & \; \text{if} \; v_j(n) = 0
\end{cases}
$$

Ovviamente:

$$
y_j(n) = \varphi(v_j(n))
$$

Intuitivamente, se l'attivazione attuale del neurone e' 0, allora sara' uguale
al valore che aveva precedentemente. L'attivazione potrebbe quindi cambiare o
non cambiare.

>*In questo senso, ogni neurone funziona come se fosse un automa a stati finiti,
>la cui funzione di transizione e' appunto $\varphi$*

### Funzionamento Generale

L'idea principale di queste reti e' quella di avere un neurone per ogni input,
per cui gli input sono rappresentati come vettori di features che hanno solo due
valori: $-1$ e $1$. 
Una volta presentato l'input alla rete, ogni neurone corrispondente alla
determinata feature verra' attivato o meno a seconda del valore dell'input.
Successivamente, si applica la funzione di attivazione a neuroni scelti in modo
casuale fino a quando nessun neurone cambia piu' il suo valore (*stato
stabile*).
In questo senso, l'**output** della rete non e' nient'altro che lo stato stabile
raggiunto dalla rete.

> *Qualsiasi sia la configurazione di input, si raggiungera' **sempre** uno stato
> stabile in un numero finito di passi.*

Una rete di Hopfield non ha un solo stato stabile, ma ce ne possono essere piu'
di uno. Come regola generale, vale che se ho uno stato stabile, avro' che anche
il suo **negato** e' uno stato stabile.

### Apprendimento (Storage Phase)

Come detto in precedenza, la rete ha diverse memorie fondamentali salvate. Tali
memorie le possiamo vedere come degli *attrattori*: stati stabili verso la quale
la rete converge con l'iterazione ripetuta della funzione di attivazione.
L'apprendimento (la fase di storage) non e' altro che aggiustare i pesi in modo
tale da rendere una particolare memoria un *attrattore* (cioe' uno stato
stabile).

Intuitivamente, uno stato e' stabile quando:

* Tutte le unita' con la stessa attivazione sono connesse da pesi positivi
* Tutte le unita' con le attivazioni opposte sono connesse da pesi negativi

Questa principio intuitivo e' una generalizzazione del Principio di Hebb.

> **Principio di Hebb**: *"Neurons that fire together, wire together"*

Per cui se due neuroni sono entrambi attivi ($1$), la sinapsi che li colleghera'
dovra' avere un valore alto ($1$). In questo modo l'attivazione di uno rafforza
l'attivazione dell'altro. Come detto la nostra regola e' una generalizzazione,
per cui anche due neuroni non attivi ($-1$) verranno lo stesso connessi da pesi
positivi.
Al contrario, i neuroni discordi devono avere pesi sviluppati negativi, in modo
da indebolirsi.

Vediamo piu' nel dettaglio la regola di update dei pesi. Prendiamo un caso
specifico e ipotizziamo di voler memorizzare solamente una memoria fondamentale
$f_1$. Come gia' detto, non e' nient'altro che un vettore con tante quante
componenti sono i neuroni $N$.
Apprendere questa memoria corrispondera' quindi ad applicare la seguente regola
per tutti i pesi $i, j$

$$
w_{j, i} = f_1(i) \cdot f_1(j)
$$

dove $f_1(i)$ e' l'*i-esima* componente di $f_1$ (vale lo stesso per $j$).
Questo perche' se $i$ e $j$ hanno valori discordi, allora anche il peso sara'
negativo, mentre se hanno segno concorde avranno peso positivo. Non ci resta che
generalizzare ad un numero arbitrario di memorie fondamentali. Ipotizziamo
quindi di avere $M$ memorie fondamentali $f_1, \dots f_M$. La regola
generalizzata non e' nient'altro che la *media* della singola regola di update
applicata ad ogni memoria:

$$
w_{j,i} = \frac{1}{M} \sum^M_{k=1} f_k(i) \cdot f_k(j) \; \;\; \text{ if } j\neq i
$$

> *Questa regola viene applicata una sola volta, per cui in questo senso si parla
> di **one-shot learning***.

### Inferenza (Information Retrieval)

Come gia' detto, una volta memorizzate le memorie fondamentali, possiamo
utilizzare la rete per fare information retrieval. L'algoritmo per far cio' ha
una garanzia teorica di convergenza ed e' particolarmente semplice.

1. Dato il segnale $x^*$, inizializza tutti i neuroni con i valori
   corrispondenti al segnale
2. Itera fino alla convergenza applicando la regola di update $\varphi$ a
   neuroni scelti in modo casuale
3. Se per ogni neurone l'applicazione della regola non genera un nuovo valore,
   allora abbiamo raggiunto uno stato stabile e si puo' terminare ritornando
   tale stato

#### Teorema di convergenza

Il teorema di convergenza si basa su una misura di **Energia**. L'energia misura
la propensione della rete a cambiare stato. Piu' l'energia e' alta, piu' sara'
possibile che la rete cambi stato.
Ogni stato ha un valore associato di energia, in generale ci sono $2^N$ stati
possibili in una rete con $N$ neuroni. Conseguentemente avremo lo stesso numero
finito di valori di energia.

Intuitivamente il teorema di convergenza dice che ogni volta che si applica
l'update rule, l'energia totale della rete diminuira' ad ogni stato successivo.
Ma siccome il numero di valori di energia possibili e' effettivamente finito, si
arrivera' prima o poi ad un punto in cui l'energia associata ad uno stato sara'
$0$. Questo stato e' appunto uno *stato stabile*.

Formalmente, l'energia di un determinato stato e' calcolata nel modo seguente:

$$
E(n)= -\frac{1}{2} \sum_i^N \sum_j^N w_{i, j}(n) \cdot  y_i(n) \cdot  y_j(n) 
$$

L'energia misura quanto e' propensa la rete a cambiare stato, per cui e' una
misura che vorremmo vada a 0 dopo ogni iterazione. Ogni prodotto $w_{i, j}(n)
\cdot  y_i(n) \cdot  y_j(n)$ e' positivo quando:

* $y_i(n)$ e $y_j(n)$ hanno lo *stesso segno* e $w_{i,j}(n)$ e' *positivo*
* $y_i(n)$ e $y_j(n)$ hanno *segno opposto* e $w_{i,j}(n)$ e' *negativo*

Iniziamo con lo scomporre dalla somma un generico $y_k$, per cui otteniamo

$$
E = -\frac{1}{2} \sum_{i \neq k}^N \sum_{j\neq k}^N w_{i, j} \cdot  y_i \cdot  y_j + 2\sum_{j \ne k}^N w_{kj} \cdot y_k \cdot y_j   
$$

Facciamo la stessa cosa, ma consideriamo invece $E'$, cioe' l'energia dopo che
$y_k$ e' cambiato di stato ed e' diventato $y_k'$

$$
E' = -\frac{1}{2} \sum_{i \neq k}^N \sum_{j\neq k}^N w_{i, j} \cdot  y_i \cdot  y_j + 2\sum_{j \ne k}^N w_{kj} \cdot y_k' \cdot y_j
$$

Allora, la differenza tra l'energia al passo attuale $E$ e quella al prossimo
passo $E'$ e'

$$
E - E' = \left( -\sum_{j \ne k} w_{kj} \cdot y_j \right) \cdot (y_k - y_k')
$$

Per cui possiamo distinguere due casi:

* Se $y_k$ passa da $+1$ a $-1$, allora $(y_k - y_k') > 0$ e $\sum_j w_{kj} y_j
  < 0$
* Se $y_k$ passa da $-1$ a $+1$, allora $(y_k - y_k') < 0$ e $\sum_j w_{kj} y_j
  > 0$

Se si sostituiscono i valori all'interno della relazione, si ottera' sempre che
$E- E' >0$ per cui $E > E'$.

Abbiamo dimostrato che ad ogni iterazione l'energia si abbassa. $\blacksquare$ 

### Pro

1. Sono in grado di completare pattern parziali
2. Imparano a generalizzare: riescono a capire che un input simile ad una
   memoria fondamentale, appartiene di fatto alla classe di quella memoria
   fondamentale 
3. Fault tolerant: anche se alcune sinapsi vengono rimosse, la rete continua
   comunque a funzionare (posto che la rete sia sufficientemente grande)
4. Sono in grado di estrarre prototipi: se vengono presentate degli input simili
   a tante memorie fondamentali, la rete si stabilizzera' in un punto in mezzo
   che e' prototipo di tutte le memorie fondamentali
5. La regola di apprendimento si basa sul principio di Hebb, che e' un principio
   *biologicamente plausibile*

### Contro/Problematiche

1. Esistono stati stabili imprevisti: come detto, l'opposto di uno stato stabile
   e' anch'esso uno stato stabile. Inoltre, l'apprendimento di piu' memorie
   fondamentali insieme introduce altri stati stabili detti *spuri* che non si
   volevano introdurre. In questo senso, questi stati *interferiscono* con gli
   stati delle memorie fondamentali.
2. Non tutte le memorie fondamentali possono essere resi stati stabili.
3. La capacita' di storage di memorie fondamentali e' limitata. In generale, una
   regola ci dice che possiamo memorizzare $0.14 \cdot N$ memorie fondamentali
   per una rete di $N$ dimensioni.
