# Deep Restricted Boltzmann Machines

Le RBM possono essre combinate tra di loro per ottenere modelli deep piu'
complessi. Il problema delle reti profonde e' che e' difficile trovare dei
minimi globali. Al crescere del numero dei layers auenta anche la difficolta' di
apprendimento. Le reti convolutional pongono dei limiti architetturali per
sorpassare questo problema: I layer non sono tutti densi, i pesi sono condivisi,
ecc.. L'idea delle Deep RBM per risolvere questo problema e' diversa e si basa
sul concetto di *pre-training*. 

>*Al posto di inizializzare i pesi in modo casuale, si cerca di inizializzarli
>in modo intelligente*

Nella letteratura, la fase di pretraining e' stata implementata in due modi
diversi, a seconda del metodo con cui si inizializzano i pesi in maniera
informata:

1. Autoassociators
2. Restricted Boltzmann Machines

Gli autoassociators sono delle reti feedforward con un solo livello hidden, il
cui compito e' quello di *impare a riprodurre a livello dell'output l'input
stesso*.

> *Associa un determinato input a se stesso passando attraverso un livello
> hidden*

Il training di un autoassociator viene fatto mediante backpropagation in cui
l'input e' anche il target. In questo senso, l'apprendimento e'
*non-supervisionato*.
Il metodo consiste nel prendere a coppie i livelli della rete profonda in cui
fare pretraining, li si considera come un autoassociator e si va a fare
l'operazione descritta in precedenza: provando a far matchare input e output.
Sperabilmente la rete dovrebbe partire in uno spazio dei pesi vicino ad un buon
minimo.

Come detto, al posto degli autoassociators possiamo utilizzare anche le
Restricted Boltzmann Machines.

>*"To recognize shapes, first learn to generate images"*

Il procedimento e' simile a quello visto in precedenza. Si inizia a considerare
l'input layer della rete profonda e il livello immediatamente successivo e li si
tratta come una RBM. (Il livello visible sara' l'input layer e quello successivo
l'hidden). Successivamente si applica l'algoritmo di contrastive divergence a
questi due layer, trattandoli appunto come se fossero una RBM. Cosi' facendo,
questi layer saranno in grado di generare al livello visibile il training set
con pochi errori.
Una volta fatto cio', si passa al prossimo layer, per cui quello che prima era
hidden diventa visible, e il layer successivo nella rete profonda diventa il
layer hidden della nuova RBM. Essenzialmente si avanza considerando i layers
dell'architettura profonda a coppie.

Consideriamo un esempio in cui abbiamo una rete deep a 4 livelli ($i, h_1, h_2,
o$).

* Considera i livelli $(i, h_1)$ come una RBM ($i$ *input*, $h_1$ *hidden*) e
  fai il training con l'algoritmo di CD *utilizzando gli esempi del training
  set*
* Considera i livelli $(h_1, h_2)$ come una RBM ($h_1$ *input*, $h_2$ *hidden*)
  e fai il training con l'algoritmo di CD *utilizzando i segnali di output
  salvati al livello precedente $h_1$*
* Considera i livelli $(h_2, h_o)$ come una RBM ($h_2$ *input*, $o$ *hidden*) e
  fai il training con l'algoritmo di CD *utilizzando i segnali di output salvati
  al livello precedente $h_2$

Dopo aver applicato questa tecnica, si succede una fase cosiddetta di
*fine-tuning* in cui viene fatto il training tramite *backpropagation*
(Stochastic Gradient Descent + Autodiff)
Tramite questa tecnica di RBM stacking, e' possibile ottenere diversi modelli.
L'applicazione piu' classica di questa tecnica permette di ottenere modelli
discriminativi, ma variando il numero di unita' hidden di ogni layer possiamo
ottenere anche degli *autoencoders* oppure dei modelli *generativi*.

### RBM-Based Deep Autoencoders

L'idea degli autoencoders e' quella di utilizzare queste *pile* di RBM in modo
da fare un lavoro di *compressione* dei dati. Per fare cio' si crea
un'architettura composta da RBM impilate tra loro con sempre meno *hidden
units*, cosi' che si riduca progressivamente la dimensionalita' dei dati. Questa
struttura e' detta *encoder* per appunto la sua natura di codifica dei dati in
dimensionalita' piu' basse.
Il *decoder* e' invece una struttura simile all'*encoder* che viene creata
facendo il training dei vari livelli considerandoli in ordine inverso. Il
compito del *decoder* e' quello di riportare alla dimensione originale i dati
compressi.

### Deep Belief Networks

Le DBN sono dei modelli *generativi*, cioe' hanno il compito di approssimare
molto bene la distribuzione di probabilita' congiunta di *features* e *target*.
Le DBN hanno un'importante differenza rispetto alle altre architetture basate su
questo metodo di stacking, ed e' nella fase di *fine tuning*. 
L'algoritmo per far cio' e' chiamato **Contrastive Wake - Sleep**.
Tale algoritmo necessita di aggiungere dei pesi che non sono parte integrante
del modello e sono necessari solo all'esecuzione dell'algoritmo detti *pesi
discriminativi*, che vanno in direzione dal basso verso l'alto (questo e'
ragionevole dal momento che se andiamo dall'alto verso il basso otteniamo un
modello discriminativo)
L'algoritmo consiste poi nell'alternare due fasi per ogni elemento del training
set: 

1. Fase di *"wake up"*: L'elemento corrente del training set viene presentato al
   livello visible propagando l'attivazione dei livelli sovrastanti fino a
   raggiungere l'ultimo livello. Ogni qual volta che si passa da un livello a
   quello sovrastante, (si utilizzano dei pesi discriminativi che non sono parte
   del modello) si vanno ad aggiustare i pesi che vanno invece nella direzione
   opposta (pesi generativi). In questo modo, dalla configurazione hidden appena
   ottenuta, aumenteranno le chance in futuro di generare lo stimolo che le ha
   causate (muovendosi verso il basso).
2. Fase di *"sleep"*: Si parte dal layer piu' esterno (quello di output) che
   conterra' una configurazione data dalla fase di *"wake up"*, facendo
   l'inverso: ogni volta che si passa da un livello a quello sottostante, (pesi
   generativi) allora si vanno ad aggiustare i pesi nella direzione opposta
   (pesi discriminativi), in modo che il segnale al layer piu' alto possa essere
   piu' plausibile a partire dal segnale che e' stato ottenuto al livello
   sottostante.

>*I pesi discriminativi fanno parte solo dell'algoritmo e non sono parte del
>modello generativo in se*

L'idea di questo algoritmo e' quella di *"cristallizzare"* in un certo senso i
pattern che sono stati appresi nella fase di *pre-training*.
