# Extreme Learning Machines

Affermazione principale: Una rete FF con un livello nascosto di funzioni
sigmoidi, i pesi  e i bias tra il livello input e quello nascosto, possono
essere scelti randomicamente e non piu' modificati, posto che le funzioni di
trasferimento del livello nascosto siano infinitamente differenziabili (le
sigmoidi sono infinitamente differenziabili).
Le ELM sono nate essenzialmente per risolvere i problemi di regressione, ma
possono essere adattate anche a risolvere task di classificazione.

Le conseguenze di questa affermazione sono essenzialmente 2:

1. Si puo' evitare di fare l'apprendimento su una grande quantita' di pesi:
   quelli del primo livello.
2. Una volta fissati i pesi del primo livello, i pesi tra il livello nascosto e
   il livello output possono essere determinati in maniera *analitica*. 

Partiamo col definire il problema dal punto di vista matematico, proprio come e'
stato fatto nel caso delle Reti Neurali Multiradiali.

> Segue un cambio di notazione rispetto a quella utilizzata dalla professoressa
> (per rimanere in linea con il paper)

Siano:

* $g(\cdot)$ una funzione di attivazione
* $\overline{x}_i$ l'esempio *i-esimo*
* $\overline{\beta}_i$ il vettore dei pesi tra l'*i-esimo* neurone di output e
  l'hidden layer
* $\overline{y}_i$ l'output della rete per l'esempio *i-esimo* (ha tante
  componenti quanti i neuroni in output)

Possiamo espandere la notazione vettoriale in modo da riscrivere tutto in
notazione matriciale:

$$
H \cdot \beta = y
$$

dove:

* $H$ e' la matrice delle funzioni di trasferimento applicate al campo dei neuroni hidden (l'output dell'input layer)
* $\beta$ e' il vettore dei pesi tra i neuroni hidden e i neuroni di ouput
* $y$ e' l'output della rete

Come detto, se noi volessimo una soluzione analitica, vorremmo ottenere una
soluzione di questo sistema, ma in generale sappiamo che la matrice non e' quasi
mai invertibile. Vorremmo quindi ottenere

$$
H \cdot \beta \approx T
$$

procedendo quindi per la pseudoinversa otteniamo che e' equivalente a

$$
\beta = H^+ \cdot T
$$

dove $T$ e' il target desiderato.
L'apprendimento di queste reti e' riassunto quindi dai seguenti passaggi:

> *Assegnamento pesi random del layer in input + calcolo rimanenti per
> pseudoinversa*

Secondo Hwang questo tipo di apprendimento permette di ottenere delle
performance migliaia di volte migliori rispetto all'algoritmo di
backpropagation, per di piu' ottenendo performance di generalizzazione migliori.

Questo perche' se ipotizziamo che la superficie dell'errore sia determinata da
due coordinate $w_h, w_i$ , per semplicita' un solo peso hidden e un solo peso
in input, abbiamo che fissando il valore di una coordinata, lo spazio di ricerca
delle soluzioni si vada di conseguenza a ridurre drasticamente. Cio'
corrisponderebbe a ridurre la ricerca da uno spazio 3-dimensionale a uno
bi-dimensionale, determinato dal piano che interseca la soluzione ottimale.

In realta' Hwang va ad ignorare un elemento fondamentale: fissare i valori in
modo random, non e' detto che ci posizioni l'iperpiano in un punto che interseca
un ottimo (locale).

> L'algoritmo in se dovrebbe essere iterato piu' volte in modo da posizionare il
> piano in punti differenti

Il metodo continua ad essere di interesse pero' per diverse ragioni:

* E' comunque competitivo dal punto di vista di performance
* Avendo necessita' di essere generalizzato, predillige le scelte dei pesi di
  secondo livello *piccoli*

Il fatto che i pesi siano piccoli e' spesso associato al fatto che le reti con i
pesi del livello hidden piccoli siano piu' in grado di generalizzare rispetto ad
altre.

> **Teorema**: Dati $N$ esempi distinti arbitrari scelti in maniera casuale
> formati come coppie $(\overline{x}_i, t_i)$, e una rete con $N$ neuroni hidde,
> per ogni insieme di pesi e bias $\overline{w}_i, b_i$ scelti in maniera random
> da un qualsiasi insieme continuo $\overline{w}_i \in \mathbb{R}^n, b_i \in
> \mathbb{R}$, allora con propabilita' $1$, la matrice $H$ e' invertibile, e la
> distanza tra $H \beta$ e $T$ puo' essere resa nulla.

L'algoritmo di apprendimento sfrutta questi due risultati teorici per apprendere
la rete.

## Algoritmo di Apprendimento

Dati:

* Un training set $N = \{ (x_i, t_i) | x_i \in \mathbf{R}^n, t_i \in
  \mathbf{R}^m, i = 1, \dots, N\}$
* Una funzione di attivazione $g(\cdot)$
* Il numero di nodi hidden $\tilde{N}$
* Il target $T = [t_1, \dots t_N]^T$

1. Assegna randomicamente i pesi input $w$ e i bias $b$
2. Calcola la matrice di output dei neuroni hidden $H$
3. Calcola i pesi output $\beta$ per pseudoinversione $\beta = H^+ T$

Il numero di neuroni hidden $\tilde{N} << N$.

> Tanto piu' $\tilde{N}$ si avvicina al valore $N$, tanto piu' migliora
> l'apprendimento (non significa che migliori la generalizzazione)

Si deve inoltre fare attenzione al fatto che il metodo della pseudoinversa e'
numericamente molto instabile quando la matrice $H^T H$ e' *quasi-singolare*
Questo problema possiamo risolverlo andando ad applicare una regolarizzazione.
La regolarizzazione non e' nient'altro che la somma di un termine chiamato
*termine di regolarizzazione*. Applichiamo questa tecnica all'errore

$$
E = E_D + \lambda E_{\beta}
$$

Minimizzare $E$ non consiste piu' solo nel minimizzare l'errore di discrepanza
$E_D$ che gia' conosciamo, ma anche nel minimizzare il secondo termine.
Questo porta ad un vantaggio principale:

1. Si controlla meglio l'overfitting. In questo modo posso tollerare anche dei
   pesi che si avvicinano al target ma non uguali. Questo perche' la
   regolarizzazione produce pesi che in valore assoluto sono piccoli, ed esiste
   una serie di teoremi dimostrati che dicono che piu' piccola e' la norma dei
   pesi, migliori sono le performance di generalizzazione.

2. Allontana la matrice dalla condizione di *quasi-singolarita'*, che porterebbe
   a soluzioni numericamente instabili. Questo perche' la soluzione diventa
   $\beta^* = (H^T H + \lambda I)^{-1} H^T T$, e posso quindi fare tuning del
   parametro $\lambda$ per evitare la quasi singolarita'.
