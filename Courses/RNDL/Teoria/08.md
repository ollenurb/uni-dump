# Boltzmann Machines

> **Problema**: *Le reti di Hopfield incorrono in stati **spuri***

Come abbiamo visto esiste un limite di memorie calcolabile per evitare di
incorrere in questo problema: $0.14 \cdot N$ memorie (dove $N$ e' il numero di
neuroni)
Se noi non volessimo seguire questa regola, come possiamo eliminare questi stati
stabili spuri? Questa e' la domanda che ha dato origine alle Boltzmann Machines.
Una delle idee principali proposte consiste nel lasciare che la rete finisca in
uno stato spuro a partire da uno stato iniziale casuale. In caso finisca in
questo stato, si applica una procedura di *unlearning* cioe' si va a rimuovere
la memoria di quello stato spuro.

>*Il procedimento di **unlearning** e' stato proposto come modello per spiegare a
>cosa servano effettivamente i **sogni***

Un'altra idea che fu proposta fu anche quella di cambiare l'architettura
fondamentale della rete di Hopfield. L'idea fondamentale e' che al posto di
utilizzare la rete per salvare *memorie*, la si usa per costruire
*interpretazioni* dell'input.

Rispetto alle reti di Hopfield, le RBM vanno a introdurre un layer esterno,
rendendo tutti i neuroni connessi (come la rete di Hopfield) un unico layer
hidden. Le RBM hanno quindi due layer distinti:

1. **Hidden layer**: servono a trovare correlazioni di attivazioni a livello
   visible e riforzano questi pattern a livello visible quando ne si presenta
   una versione corrotta.
2. **Visible layer**: riceve l'input e fa pattern completion.

I neuroni dell'hidden layer sono completamente connessi con tutti i neuroni del
visible layer, ma i neuroni di ogni livello non sono connessi tra loro.

La terza idea addizionale e' che le reti di Hopfield vanno solo a decrescere
l'energia totale della rete, per cui la probabilita' di finire in un minimo
locale e' molto grande in generale. Le reti di Boltzmann vanno a introdurre un
elemento di stocasticita' in modo da considerare altri stati dei neuroni e dar
modo di cercare altri minimi nella funzione dell'energia.

La regola dell'attivazione dei neuroni nelle Boltzmann Machine ha quindi anche
una componente stocastica per tenere in conto questo comportamento. Per i
neuroni hidden, la regola e' la seguente:

$$
p(s_i = 1) = \frac{1}{1 + e^{-\Delta E_i/T}}
$$

Dove $\Delta E_i=E(s_i=0)-E(s_i=1)$ e' l'*energy gap*, che indica quanto sia
propenso al cambiamento il neurone $i$, e $T$ indica la *temperatura* che
quantifica la *stabilita'*.

L'energia $E(s_i = x)$ viene calcolata come l'energia totale della rete
supponendo che $i$ abbbia il valore $x$. In realta', per definizione (e cosi'
evitare di calcolare tutte le energie totali a mano ogni volta), l'enegy gap e'
definito come:

$$
\Delta E_i=\sum_j w_{i,j} \cdot s_i + b_i
$$

Ovviamente siamo parlando di una probabilita', per cui l'attivazione sara' un
valore in $[0;1]$, per cui il vero valore sara' ottenuto da una successiva
procedura di sampling dalla distribuzione ottenuta.

>*Le macchine di Boltzmann sono modelli Generativi: Imparano a riprodurre ad un
>livello visivo il training set. In altri termini, modellano la probabilita'
>congiunta $P(X, Y)$*

L'algoritmo di apprendimento e' chiamato *Contrastive Divergence*. Esso si basa
sulla seguente idea: quando si presenta un esempio alla rete, se ne calcola
l'attivazione per ogni neurone. Una volta calcolata, si ripete lo stesso
passaggio utilizzando pero' la rete il cui stato e' stato calcolato al passo
precedente. In altri termini, si fa un "applicazione ripetuta" del passaggio per
un numero molto grande di volte. Idealmente, al tendere di questo numero
all'infinito, otterremo uno stato verso cui la rete converge.

L'idea di update dell'algoritmo e' quindi quella di assegnare i pesi in modo che
la discrepanza tra l'esempio che e' stato presentato alla rete e lo stato finale
(quello dopo l'applicazione di infiniti passi di update) e' minima (o nulla).

Sorprendentemente, il numero di passi per ottenere questo stato a cui tende la
rete non e' infinito, ma sono solo 2. Con questa conoscenza, si puo' costruire
l'algoritmo di apprendimento, che consiste nei seguenti passaggi:

* Si presenta un esempio alla rete forzando l'attivazione dei neuroni visible ad
  essere pari ai valori delle features dell'esempio (*visible clamping*)
* Si calcolano le attivazioni dei neuroni hidden (facendo samplig dalle
  probabilita' calcolate)
* Date le attivazioni dei neuroni hidden, si calcolano le attivazioni dei
  neuroni visible
* Si ri-calcolano nuovamente le attivazioni dei neuroni hidden
* Per ogni coppia di neuroni $i,j$ ($i$ visible, $j$ hidden) si valuta la
  differenza tra il prodotto dell'attivazione del neurone visible $v_i$ e
  dell'attivazione del neurone hidden $h_j$ allo stato iniziale, e lo stesso
  prodotto ma allo stato finale. In altri termini:

$$
<v_i h_j>^0 - <v_i h_j>^1
$$

dove $<\cdot>^k$ indica lo stato $k$-esimo. L'update rule e' quindi  

$$
\Delta w_{i,j} = \eta (<v_i h_j>^0 - <v_ih_j>^1)
$$

> *Le singole unita' hidden vanno a riconoscere determinate porzioni del
> pattern*

Le unita' hidden si fanno carico di attivare determinate porzioni di unita'
visible. In questo modo, se un pattern corrotto attiva un determinato neurone
hidden, questo andra' ad attivare di conseguenza le unita' visible ad esso
collegate per ricostruire il pattern che "riconosce".
