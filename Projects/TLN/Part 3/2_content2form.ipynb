{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e553f6c-d09c-4f05-8e78-12697ceb28f2"
      },
      "source": [
        "# Esercitazione 2 - content2form\n",
        "\n",
        "Studenti:\n",
        "\n",
        "- Brunello Matteo (mat. 858867)\n",
        "- Caresio Lorenzo (mat. 836021)\n",
        "\n",
        "*Consegna*: i comuni dizionari a cui siamo abituati partono dalle parole, ovvero dalla forma, per arrivare al contenuto. Esistono alcuni tipi di dizionario chiamati dizionari analogici che funzionano ”al contrario”, ovvero non si ricerca per parola ma per definizione. Questo tipo di ricerca viene chiamata ricerca onomasiologica, ovvero si parte dal contenuto per arrivare alla forma. Proprio su questo si basa la seconda esercitazione. Sempre partendo dai dati sulle definizioni, si richiede di provare a costruire un sistema che utilizzi la molteplicità delle definizioni per risalire al termine \"target\" in maniera automatica. Non si richiede di \"indovinare\" ogni termine, ma di avvicinarsi (almeno semanticamente) alla risposta. Provare più soluzioni, includendo meccanismi di filtro delle definizioni (ad es. escludendo quelle meno informative o con caratteristiche particolari), di ricerca nell'albero tassonomico di WordNet (provando a partire da candidati \"genus\", secondo il principio Genus-Differentia), ecc.\n",
        "\n",
        "La soluzione fornita è di seguito formulata nelle sue generalità:\n",
        "\n",
        "- Per ogni *forma target*, si identifica un *genus* candidato (o un insieme di *genera candidati*) e si raccoglie del materiale lessicale composto dalle parole (lemmatizzate) presenti nella varie descrizioni;\n",
        "- Per ogni *genus candidato*, si ottiene il (o i) synset di riferimento e ne si raccolgono gli iponimi. Per ogni synset iponimo si raccoglie del materiale lessicale (lemmatizzato) associato: una *firma* composta dai suoi lemmi, dalla glossa e dagli eventuali esempi d'uso;\n",
        "- Si reitira la raccolta degli iponimi e del loro materiale lessicale per un numero (parametrizzabile) di livelli dell'albero di WordNet (si tratta di una visita in ampiezza della multi-gerarchia WN);\n",
        "- Infine, per ogni *forma target*, si calcola l'overlap tra il materiale lessicale ottenuto dalle definizioni d'esempio del dataset e tra quello degli iponimi, andando a visualizzare gli iponimi con maggiore overlap (che costituiscono quindi delle *forme candidate*)."
      ],
      "id": "2e553f6c-d09c-4f05-8e78-12697ceb28f2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2cb073e-f4a9-4d7d-85d5-b147096c7959",
        "outputId": "1386981f-e2b5-4e44-f6bd-5757ef666fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  8514  100  8514    0     0  11618      0 --:--:-- --:--:-- --:--:-- 11615\n"
          ]
        }
      ],
      "source": [
        "# Open the inspect element into your moodle session, then paste the \"MoodleSession\" field value in the storage/cookies tab\n",
        "moodle_session_cookie = 'ifbrmeeravqdsr5itc75gad5kc'\n",
        "\n",
        "!curl --cookie 'MoodleSession={moodle_session_cookie}' \"https://informatica.i-learn.unito.it/pluginfile.php/366022/mod_folder/content/0/TLN-definitions-23.tsv?forcedownload=1\" -o definitions.tsv"
      ],
      "id": "c2cb073e-f4a9-4d7d-85d5-b147096c7959"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCGMiQ4IrqKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c70aba-f4e4-407b-c1b8-6b32974aa0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "id": "tCGMiQ4IrqKf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofubCtLv-KZh"
      },
      "source": [
        "### Pre-processing del dataset\n",
        "\n",
        "Sul dataset dato si effettuano due tipologie di *pre-processing* in base all'utilizzo che se ne vuole fare: per il calcolo finale dell'overlap, è semplicemente necessario tokenizzare le definizioni, lemmatizzarne le parole e filtrare eventuali parole spurie; per il calcolo dei *genera*, oltre alle fasi appena elencate, è necessario andare a valutare solo i sostantivi, e a tale scopo si utilizzerà un PoS Tagger fornito da NLTK.\n",
        "\n",
        "Attualmente si evita di fare un vero e proprio controllo qualità sulle definizioni del dataset (come proposto come possibilità a lezione), piuttosto, dopo la fase di tokenizzazione, si eliminano invece delle stringhe spurie o delle parole troppo generiche per essere utili (`eg` *object*, o le parole target stesse che si stanno cercando, presenti in alcune definizioni)."
      ],
      "id": "ofubCtLv-KZh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7IPlfB72WEc"
      },
      "outputs": [],
      "source": [
        "stopwords = set(stopwords.words('english') + list(string.punctuation))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def tokenize_and_lemmatize_sentence(sentence):\n",
        "  return [lemmatizer.lemmatize(word) for word in word_tokenize(sentence.lower()) if word not in stopwords and not check_if_bad_word(word)]\n",
        "\n",
        "# Tokenize a sentence and lemmatize all its noun, filtering out all the stopwords, punctuation marks and the identified bad words\n",
        "def get_lemmatized_nouns_in_sentence(sentence):\n",
        "  nouns = [word for (word, pos) in nltk.pos_tag(word_tokenize(sentence.lower())) if(pos[:2] == 'NN')] # Get tokenized nouns via NLTK\n",
        "  return [lemmatizer.lemmatize(noun) for noun in nouns if noun not in stopwords and not check_if_bad_word(noun)] # Lemmatize nouns and filter bad words\n",
        "\n",
        "def check_if_bad_word(word):\n",
        "  return word in [\"'s\", \"n't\", 'u', 'ca', 'object', 'entity', 'something', 'door', 'pain'] # Derived empirically by looking at the tokenized dataset"
      ],
      "id": "S7IPlfB72WEc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz98zvjUG0VB"
      },
      "source": [
        "Si carica quindi il dataset e si stampa una selezione di definizioni pre-processate (nelle due modalità) come sopra."
      ],
      "id": "xz98zvjUG0VB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv6XVHST3GvL"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Load definitions excluding the line number,\n",
        "# returning the result as a dictionary\n",
        "def load_definitions(path: str, sentence_processor = lambda x: x):\n",
        "  result = {}\n",
        "  with open(path, 'r') as f:\n",
        "    content = list(csv.reader(f, delimiter = '\\t'))\n",
        "    for i, word in enumerate(content[0][1:]):\n",
        "      result[word] = [sentence_processor(definition[i+1]) for definition in content[1:]]\n",
        "    return result"
      ],
      "id": "wv6XVHST3GvL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "turhB4y72euo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c5667b-6be7-4b71-ce02-1df03ef2e2fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized definitions:\n",
            "  door\n",
            "   ['construction', 'used', 'divide', 'two', 'room', 'temporarily', 'closing', 'passage']\n",
            "   ['opening', 'opened', 'closed']\n",
            "  ladybug\n",
            "   ['small', 'flying', 'insect', 'typically', 'red', 'black', 'spot', 'six', 'leg']\n",
            "   ['insect', 'wing', 'red', 'black', 'dot', 'many', 'culture', 'symbol', 'good', 'luck']\n",
            "  pain\n",
            "   ['feeling', 'physical', 'mental', 'distress']\n",
            "   ['feeling', 'physical', 'emotional', 'bad', 'hurt']\n",
            "  blurriness\n",
            "   ['sight', 'focus']\n",
            "   ['absence', 'definite', 'border', 'shapelessness']\n",
            "Lemmatized nouns-only definitions:\n",
            "  door\n",
            "   ['construction', 'room', 'passage']\n",
            "   ['opening']\n",
            "  ladybug\n",
            "   ['insect', 'spot', 'leg']\n",
            "   ['insect', 'wing', 'dot', 'culture', 'symbol', 'luck']\n",
            "  pain\n",
            "   ['feeling', 'distress']\n",
            "   ['feeling']\n",
            "  blurriness\n",
            "   ['focus']\n",
            "   ['absence', 'border', 'shapelessness']\n"
          ]
        }
      ],
      "source": [
        "path = 'definitions.tsv'\n",
        "\n",
        "print(\"Lemmatized definitions:\")\n",
        "lemmatized_definitions = load_definitions(path, tokenize_and_lemmatize_sentence)\n",
        "for form, definitions in lemmatized_definitions.items():\n",
        "  print(\" \", form)\n",
        "  for processed_definition in definitions[:2]:\n",
        "    print(\"  \", processed_definition)\n",
        "\n",
        "print(\"Lemmatized nouns-only definitions:\")\n",
        "nouns_only_definitions = load_definitions(path, get_lemmatized_nouns_in_sentence)\n",
        "for form, definitions in nouns_only_definitions.items():\n",
        "  print(\" \", form)\n",
        "  for processed_definition in definitions[:2]:\n",
        "    print(\"  \", processed_definition)"
      ],
      "id": "turhB4y72euo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkhWqYpy0jJD"
      },
      "source": [
        "### Calcolo dei genera\n",
        "\n",
        "Per lo svolgimento di questa esercitazione si è deciso di seguire il principio *Genus-Differentia*: ogni definizione di un concetto è composta da una parte relativa al *genus*, un concetto più generale a quello che si sta cercando di descrivere, e da una parte relativa alla *differentia*, dove si fornisce la caratterizzazione che distingue il concetto attuale rispetto ad altri a lui simili.\n",
        "\n",
        "Prendendo l'esempio del dataset, relativo al concetto di *coccinella*, «a red insect with black spots», si può identificare *insect* come il *genus* e *red* e *with black spots* come sua *differentia*.\n",
        "\n",
        "Per l'identificazione di un *genus* a partire da un insieme di definizioni si è deciso di calcolarne il sostantivo più frequente, che andrà a costituire il *genus candidato* per la data forma (da questo si calcoleranno gli iponimi per il calcolo dell'overlap finale). Per una soluzione più flessibile, al posto di derivare un singolo *genus* da un insieme di definizioni, se ne calcola un numero parametrizzabile (sempre calcolato come l'insieme dei sostantivi più frequenti)."
      ],
      "id": "WkhWqYpy0jJD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6THarYN5i_S"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Compute candidate genera as the nouns with higher frequency in the given definition collection\n",
        "def compute_candidate_genera(definitions, n=1):\n",
        "  word_list = []\n",
        "\n",
        "  # Flatten the definitions words in a single list\n",
        "  for definition in definitions:\n",
        "    word_list.extend(definition)\n",
        "\n",
        "  # Get the most frequent nouns (candidate genera) with their frequencies\n",
        "  most_frequents_nouns = Counter(word_list).most_common(n)\n",
        "\n",
        "  return [genus[0] for genus in most_frequents_nouns]"
      ],
      "id": "I6THarYN5i_S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c84fgGEI5sdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6794d69f-8280-4b4c-da2e-6c81fe7e4d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Candidate genera for door: ['room', 'access', 'space']\n",
            "Candidate genera for ladybug: ['insect', 'dot', 'luck']\n",
            "Candidate genera for pain: ['feeling', 'sensation', 'discomfort']\n",
            "Candidate genera for blurriness: ['image', 'eye', 'vision']\n"
          ]
        }
      ],
      "source": [
        "n_genera = 3 # PARAMETER\n",
        "\n",
        "candidate_genera_by_form = dict()\n",
        "\n",
        "for form, definitions in nouns_only_definitions.items():\n",
        "  candidate_genera_by_form[form] = compute_candidate_genera(definitions, n_genera)\n",
        "  print(f\"Candidate genera for {form}: {candidate_genera_by_form[form]}\")"
      ],
      "id": "c84fgGEI5sdX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oFU1zD0EPoz"
      },
      "source": [
        "È da subito evidente come per i concetti concreti (sia specifici che generali) i *genera candidati* ottenuti possono essere utili a derivare il senso relativo alle *forme target*, così come per *pain*, concetto astratto e generale, mentre per il concetto di *blurriness*, astratto e specifico, la possibilità di derivare la *forma target* dai *genera* ottenuti sarà molto bassa."
      ],
      "id": "4oFU1zD0EPoz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lOatchKJwex"
      },
      "source": [
        "### Derivazione delle forme dai genera\n",
        "\n",
        "Una volta ottenuti i vari *genera candidati* per ogni *forma target*, si va a interrogare WordNet per ottenerne i synset associati. Gli iponimi di quest'ultimi costituiranno delle *forme candidate*, su cui verranno raccolti dei materiali lessicali associati (*firme* composte da lemmi, glosse ed esempi d'uso) e su cui si calcoleranno infine gli overlap.\n",
        "\n",
        "Non ci si limiterà però solo a valutare gli iponimi del dato *genus candidato*, ma si andrà a valutare anche gli iponimi degli iponimi, e gli iponimi di questi, per un numero di iterazioni parametrizzabile, andando così a visitare (in ampiezza) la multi-gerarchia di WordNet.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "0lOatchKJwex"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZXgh3Q3PQDv"
      },
      "outputs": [],
      "source": [
        "def collect_hyponyms(sense, depth=2):\n",
        "\n",
        "  max_depth = depth\n",
        "  stack = [sense]\n",
        "\n",
        "  collected_hyponyms = []\n",
        "\n",
        "  # Breadth-First Search over hyponyms\n",
        "  while depth > 0:\n",
        "      new_stack = []\n",
        "      for node in stack:\n",
        "          hyponyms = node.hyponyms()\n",
        "          if hyponyms:\n",
        "            collected_hyponyms.extend(hyponyms)\n",
        "            new_stack.extend(node.hyponyms())\n",
        "\n",
        "      stack = new_stack # On the next iteration, the new hyponyms will be evaluated (expanded)\n",
        "      depth -= 1\n",
        "\n",
        "  return collected_hyponyms\n",
        "\n",
        "def collect_lexical_material(sense):\n",
        "  lexical_material = sense.definition() # Add the definition of the current sense\n",
        "  for lemma in sense.lemma_names(): # Add all the related lemmas of the current sense\n",
        "    lexical_material.join(lemma)\n",
        "  for example in sense.examples(): # Add (if present) examples of the current sense\n",
        "    lexical_material.join(example)\n",
        "  return tokenize_and_lemmatize_sentence(lexical_material) # Lemmatize the lexical material in order to compare it later"
      ],
      "id": "9ZXgh3Q3PQDv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SoPEcV7dhk7"
      },
      "outputs": [],
      "source": [
        "def compute_overlap(dataset_lexical_material, hyponym_lexical_material):\n",
        "  dataset_words = set(dataset_lexical_material)\n",
        "  hyponym_words = set(hyponym_lexical_material)\n",
        "  return len(dataset_words.intersection(hyponym_words))"
      ],
      "id": "3SoPEcV7dhk7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hByT6PkGVneE"
      },
      "outputs": [],
      "source": [
        "deepening_depth = 2 # PARAMETER\n",
        "\n",
        "dataset_lexical_material = {key:[] for key in lemmatized_definitions.keys()}\n",
        "\n",
        "# Collect the lexical material from the definitions contained in the dataset\n",
        "for form, definitions in lemmatized_definitions.items():\n",
        "  for definition in definitions:\n",
        "    dataset_lexical_material[form].extend(definition)\n",
        "\n",
        "hyponyms_with_overlap = {key:[] for key in lemmatized_definitions.keys()}\n",
        "\n",
        "# Compute the hyponyms and their overlap with original definitions\n",
        "for form, genera in candidate_genera_by_form.items():\n",
        "  for genus in genera:\n",
        "    genus_synsets = wordnet.synsets(genus)\n",
        "    for synset in genus_synsets:\n",
        "      hyponyms = collect_hyponyms(synset, deepening_depth)\n",
        "      for hyponym in hyponyms:\n",
        "        overlap_size = compute_overlap(dataset_lexical_material[form], collect_lexical_material(hyponym))\n",
        "        if overlap_size > 1:\n",
        "          hyponyms_with_overlap[form].append((hyponym, overlap_size))"
      ],
      "id": "hByT6PkGVneE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F-3SZbFhWbC"
      },
      "source": [
        "Una volta individuati gli iponimi con un overlap rispetto al materiale lessicale del dataset originale, li si ordina per dimensione dell'overlap e se ne stampa un numero parametrizzabile."
      ],
      "id": "6F-3SZbFhWbC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaUd5bNMhvFe"
      },
      "outputs": [],
      "source": [
        "def get_sorted_hyponyms(hyponyms, n):\n",
        "  hyponyms.sort(key=lambda a: a[1], reverse=True)\n",
        "  return hyponyms[:n]"
      ],
      "id": "yaUd5bNMhvFe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6Mr7Ncwivio",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d7fea2-7316-4979-d0d0-d4813f67bb6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "door\n",
            "   (Synset('doorway.n.01'), 8)\n",
            "   (Synset('compartment.n.02'), 4)\n",
            "   (Synset('booth.n.02'), 4)\n",
            "   (Synset('box.n.09'), 4)\n",
            "   (Synset('angle.n.01'), 4)\n",
            "ladybug\n",
            "   (Synset('ladybug.n.01'), 5)\n",
            "   (Synset('dipterous_insect.n.01'), 4)\n",
            "   (Synset('lacewing.n.01'), 4)\n",
            "   (Synset('thrips.n.01'), 4)\n",
            "   (Synset('leaf_miner.n.01'), 3)\n",
            "pain\n",
            "   (Synset('pain.n.02'), 3)\n",
            "   (Synset('suffering.n.04'), 3)\n",
            "   (Synset('sorrow.n.01'), 3)\n",
            "   (Synset('tickle.n.01'), 3)\n",
            "   (Synset('glow.v.05'), 3)\n",
            "blurriness\n",
            "   (Synset('acuity.n.01'), 5)\n",
            "   (Synset('memory_picture.n.01'), 4)\n",
            "   (Synset('naked_eye.n.01'), 4)\n",
            "   (Synset('visual_image.n.01'), 3)\n",
            "   (Synset('collage.n.01'), 3)\n"
          ]
        }
      ],
      "source": [
        "n_hyponyms = 5 # PARAMETER\n",
        "\n",
        "for form, hyponyms in hyponyms_with_overlap.items():\n",
        "  sorted_hyponyms = get_sorted_hyponyms(hyponyms, n_hyponyms)\n",
        "  print(form)\n",
        "  for hyponym in sorted_hyponyms:\n",
        "    print(\"  \", hyponym)"
      ],
      "id": "k6Mr7Ncwivio"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDmfl-NXmn8g"
      },
      "source": [
        "Come previsto, per *door*, *ladybug* e *pain* la *forma candidata* con maggiore overlap corrisponde a quella *target*, mentre per *blurriness*, concetto astrattato e specifico, i cui *genera candidati* non risultavano particolarmente azzeccati, le *forme candidate* ottenute risultano associate allo stesso campo semantico della *forma target*, quello della percezione visiva, ma non corrispondono con esattezza al *target* stesso (il synset WordNet associato a *blurriness* è `indistinctness.n.01`).\n",
        "\n",
        "In generale si può concludere che, vista anche la non particolare sofisticatezza della soluzione adottata, utilizzare il principio *Genus-Differentia* può portare a dei risultati soddisfacenti per il task di *content2form*."
      ],
      "id": "tDmfl-NXmn8g"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}