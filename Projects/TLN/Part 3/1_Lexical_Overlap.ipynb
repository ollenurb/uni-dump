{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUgaq1G1JuH7"
      },
      "source": [
        "# Esercitazione 1 - Lexical Overlap\n",
        "\n",
        "Studenti:\n",
        "\n",
        "- Brunello Matteo (mat. 858867)\n",
        "- Caresio Lorenzo (mat. 836021)\n",
        "\n",
        "*Consegna*: misurazione dell’overlap lessicale tra una serie di definizioni per concetti generici/specifici e concreti/astratti. Partendo dai dati sulle definizioni (presente nella cartella \"dati\" su Moodle), si richiede di calcolare la similarità $2$-a-$2$ tra le definizioni (ad es. usando la cardinalità dell'intersezione dei lemmi normalizzata sulla lunghezza minima delle definizioni), aggregando (ed effettuando la media degli score di similarità) sulle due dimensioni (concretezza / specificità)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caricamento e preprocessing del dataset\n",
        "\n",
        "Da una prima valutazione del dataset fornito in formato `tsv` ne emerge che le varie colonne si riferiscono ai termini, mentre le righe si riferiscono alle definizioni associati ad essi. Per ottenere un formato atto a calcolare la similarità, ogni definizione viene pre-processata trasformandola in tokens (che in questo caso sono *parole*) rimuovendo eventualmente la punteggiatura. Una volta ottenuta una lista di token rappresentanti la definizione, ogni token viene successivamente lemmatizzato utilizzando WordNet.\n",
        "\n",
        "Il risultato del caricamento del dataset è un dizionario che ha come chiavi i termini e come valore una lista di definizioni tokenizzate."
      ],
      "metadata": {
        "id": "OK6G9FfsKc2u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ4-TCGLPeff",
        "outputId": "5fcff8af-813d-464f-b797-8f001e1b30f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  8514  100  8514    0     0   9355      0 --:--:-- --:--:-- --:--:--  9356\n"
          ]
        }
      ],
      "source": [
        "# Open the 'inspect element' tab while browsing into your moodle session, then paste the \"MoodleSession\" field value in the storage/cookies tab\n",
        "moodle_session_cookie = 'b39kmpptestnpipi4a4v8vcslq'\n",
        "\n",
        "!curl --cookie 'MoodleSession={moodle_session_cookie}' \"https://informatica.i-learn.unito.it/pluginfile.php/366022/mod_folder/content/0/TLN-definitions-23.tsv?forcedownload=1\" -o definitions.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4ssISLoRFyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49164f48-2a43-4fa6-f225-77d994847a34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Define a set of tokens that must be filtered out\n",
        "stop = set(stopwords.words('english') + list(string.punctuation))\n",
        "\n",
        "# Define the lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Tokenize a sentence, filtering out all stopwords and punctuations in the process.\n",
        "# The function then \"tries\" to lemmatize each token using Wordnet.\n",
        "def tokenize(sentence):\n",
        "  return [lemmatizer.lemmatize(i) for i in word_tokenize(sentence.lower()) if i not in stop]\n",
        "\n",
        "# Load definitions excluding the line number,\n",
        "# returning the result as a dictionary\n",
        "def load_definitions(path: str):\n",
        "  result = {}\n",
        "  with open(path, 'r') as f:\n",
        "    content = list(csv.reader(f, delimiter = '\\t'))\n",
        "    for i, word in enumerate(content[0][1:]):\n",
        "      result[word] = [tokenize(definition[i+1]) for definition in content[1:]]\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calcolo overlap lessicale\n",
        "Come suggerito dalla consegna, definiamo la similarità come overlap lessicale. Successivamente si calcola l'overlap medio, considerando le varie definizioni (precedentemente tokenizzate) a due a due."
      ],
      "metadata": {
        "id": "cjS6VM2fTZmS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4A1w29ejB1E"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "from statistics import mean\n",
        "\n",
        "# Compute the similarity between two definitions\n",
        "def similarity(d1, d2):\n",
        "  d1, d2 = set(d1), set(d2)\n",
        "  return len(d1 & d2) / min(len(d1), len(d2))\n",
        "\n",
        "# Compute the average pairwise similarity between definitions for each word\n",
        "def compute_overlaps(defs):\n",
        "  for word in defs.keys():\n",
        "    defs[word] = mean([similarity(d1, d2) for d1, d2 in combinations(defs[word], 2)])\n",
        "  return defs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Infine, si va a visualizzare i risultati ottenuti in un formato tabellare.\n"
      ],
      "metadata": {
        "id": "pFTl3N-uWDaE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wmp5y3Mu2-2"
      },
      "outputs": [],
      "source": [
        "def pretty_print(overlaps):\n",
        "    printable_pairs = [f'{w}: {m:0.2f}' for w, m in overlaps.items()]\n",
        "    print('+-----------+---------------------------+--------------------------+')\n",
        "    print(f'|{\"\":10s} | {\"Abstract\":25s} | {\"Concrete\":25s}|')\n",
        "    print('+-----------+---------------------------+--------------------------+')\n",
        "    print(f'|{\"Generic\":10s} | {str(printable_pairs[2]):25s} | {str(printable_pairs[0]):25s}|')\n",
        "    print(f'|{\"Specific\":10s} | {str(printable_pairs[3]):25s} | {str(printable_pairs[1]):25s}|')\n",
        "    print('+-----------+---------------------------+--------------------------+')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aor9LFEIymJs",
        "outputId": "33f85735-3aef-450a-d14f-ba1c5326f1f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------------------------+--------------------------+\n",
            "|           | Abstract                  | Concrete                 |\n",
            "+-----------+---------------------------+--------------------------+\n",
            "|Generic    | pain: 0.20                | door: 0.19               |\n",
            "|Specific   | blurriness: 0.07          | ladybug: 0.56            |\n",
            "+-----------+---------------------------+--------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Execute all the steps defined earlier\n",
        "path = 'definitions.tsv'\n",
        "definitions = load_definitions(path)\n",
        "overlaps = compute_overlaps(definitions)\n",
        "pretty_print(overlaps)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dai risultati emerge che per un concetto concreto e specifico come *ladybug* le definizioni sono molto simili tra loro ($\\approx 56\\%$), mentre per altri concetti i risultati sono meno significativi, evidente nel concetto di *blurriness*, specifico e astratto, dove l'overlap medio tra le varie definizioni è molto basso (suggerendo la difficoltà a raggiungere un consenso generale in termini di definizioni di questo concetto)."
      ],
      "metadata": {
        "id": "jRu3S_UGWzb2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}