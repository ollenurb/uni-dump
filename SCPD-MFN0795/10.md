\newpage
# Modello di programmazione Shared Memory
Programmare sistemi a memoria condivisa e' molto piu' semplice di programmare
sistemi message passing. Questo perche' il programmatore ha una visione globale
della memoria in questo tipo di sistemi, mentre nel message passing no. Si pensi
ad esempio il caso in cui si voglia sapere il valore di una determinata
variabile. Nei sistemi shared memory sarebbe immediato dal momento che la
variabile risiederebbe sicuramente in memoria, mentre nei sistemi message
passing tale variabile deve essere ricevuta da qualche altro processo ignoto.
Anche se piu' conveniente dal punto di vista di programmazione, tale paradigma
necessita di controllare gli accessi alla memoria in modo esplicito dal
programmatore tramite opportune sincronizzazioni.

> Il problema di questo tipo di sistemi e' che non hanno un'alta scalabilita' per
  delle questioni che verranno trattate successivamente. In generale, se si vuole
  vere un'alta scalabilita' e' preferibile il paradigma *message passing*, mentre
  se si si vuole avere un'applicativo con numero di UC basso si preferisce il
  paradigma *shared memory*. Questo perche' per un numero basso di UC il paradigma
  message passing e' molto piu' efficiente perche' riduce significativamente
  l'overhead della comunicazione.

Partiamo ora dalla definizione di un sistema multiprocessore a memoria
condivisa. In generale un sistema a memoria condivisa e' qualsiasi sistema in
cui ogni locazione di memoria possa essere acceduta da qualsiasi processore.
Ogni locazione di memoria ha inoltre un indirizzo univoco all'interno del range
possibile di indirizzi. In altri termini, hanno un *singolo spazio di
indirizzamento*.
Essenzialmente possiamo descrivere un sistema shared memory come un sistema di
processori connessi tra di loro e a loro volta connessi alla memoria attraverso
un sistema di interconnessione. Come gia' visto la rete di interconnessione puo'
essere di varie tipologie. Tipicamente, in qeusto tipo si sistema si impiega una
crossbar switch. I processori hanno a loro volta delle memorie di piccole
dimensioni molto performanti chiamate memorie *cache*.

**TODO: Inserire immagine Shared Memory**

Ci sono diversi metodi per programmare un sistema a memoria condivisa
multiprocessore, tra cui alcuni molti diversi tra loro:

* Utilizzando processi (*heavyweight*)
* Utilizzando threads (*lightweight*)
* Utilizzando un linguaggio completamente progettato per la programmazione
  parallela (es. Ada)
* Utilizzando routines di liberire di un linguaggio di programmazione
  sequenziale
* Modificando la sintassi di un linguaggio sequenziale creando di fatto un
  linguaggio parallelo
* Utilizzando un linguaggio sequenziale e "decorarlo" con delle direttive di
  compilazione (es. OpenMP)

Il primo approccio non e' molto utilizzato in parallel computing per il troppo
overhead causato dallo scheduling dei processi. I processi hanno un programma
completamente separato con le proprie variabili, il proprio stack e il proprio
heap, mentre i threads necessitano solamente di uno stack e un istruction
pointer. `pthreads` e' una libreria POSIX che fornisce dei costrutti di basso
livello (livello del sistema operativo) per operare con i threads. Per eseguire
un thread si utilizza la seguente chiamata, dove `&thread1` e' l'handle e
`proc1` e' una funzione da far eseguire dal thread.
```c
pthread_create(&thread1, NULL, proc1, &arg);
```
con la chiamata `pthread_join(&thread1, *status)` si puo' aspettare invece il
completamento del thread. I threads che non sono joined vengono chiamati
*detached*. Quando un thread termina, le sue risorse vengono di conseguenza
rilasciate.
Quando compiliamo un programma multitreaded, il compilatore potrebbe applicare
delle ottimizzazioni a livello di istruzioni, riodinandone l'ordine di
esecuzione. Ad esempio, lo statement
```c
a = b + 5
x = y + 4
```
potrebbe essere compilato per essere eseguito nell'ordine inverso
```c
x = y + 4
a = b + 5
```
ed essere comunque logicamente corretto. Questo tipo di ottimizzazioni viene
fatto da quasi tutti i compilatori moderni.

> Un'operazione e' detta *thread safe* se puo' essere chiamata da piu' threads
  simultaneamente e produrre sempre risultati corretti. L'I/O standard e' thread
  safe, poiche' se `println` viene chiamata da piu' threads simultaneamente, i
  caratteri non sono interfogliati.

## Accesso ai dati condivisi
Come detto in precedenza, nei sistemi a memoria condivisa bisogna prestare
particolarmente attenzione agli accessi in memoria per poter evitare eventuali
*data races*. Consideriamo due processi che vogliano aggiungere un'unita' alla
stessa variabile contenuta in memoria.
Ogni processo dovra' quindi preliminarmente leggere il contenuto della
variabile, calcolarne il risultato e poi scriverlo all'interno della variabile.
In base all'ordine in cui vengono eseguite le istruzioni di `read` si otterranno
diversi risultati. Per poter risolvere questo problema si utilizza un meccanismo
molto comune chiamato *sezione critica*

> La sezione critica e' un meccanismo che assicura che un solo processo (o
  thread) possa accedere ad una particolare risorsa alla volta

Il meccanismo di base per implementare una sezione critica e' attraverso dei
*lock* (o piu' generalmente dei *semafori*). Un lock e' una variabile binaria
che indica se un arbitrario processo/thread e' dentro la sezione critica o meno.
Funziona concettualmente come una serratura di una porta che puo' essere
chiusa/aperta. Per implementare la lock a sua volta e' necessario che sia
implementata un'istruzione a livello hardware di lettura e scrittura chiamata
`CAS` (*Compare And Swap*). Tale istruzione essenzialmente viene impiegata per
scrivere e leggere nello stesso momento una locazione in memoria, cioe' in modo
atomico.

> Se si volesse implementare un lock, un processo utilizzerebbe `CAS` andando a
  leggere e scrivere successivamente il valore 1 nella variabile lock, ignorando
  preliminarmente cio' che c'era scritto precedentemente. Una volta scritto,
  viene poi visto se la variabile era effettivamente a 0 o a 1. In caso fosse a
  1 ricicla con la stessa operazione.

In pthread i locks vengono chiusi/aperti con le primitive
`pthread_mutex_lock(&mutex1)` e `pthread_mutex_unlock(&mutex1)`. Se un thread
raggiunge un lock e lo trova chiuso, aspettera' fino a quando il lock non sara'
stato aperto. Se piu' di un thread aspetta il lock, il sistema scegliera' un
thread tra quelli in attesa per poter continuare. Ovviamente solo il thread che
chiude il lock puo' rilasciarlo aprendolo.
L'implementazione della lock puo' essere fatta mediante attesa *attiva* o
*passiva*. L'attesa attiva consiste nel ciclare fin quando il lock non e'
aperto, mentre l'attesa passiva consiste nel sospendere il processo/thread e
mandarlo in coda di sleep.
Il problema di determinare una delle due implementazioni e' difficile perche'
varia in base al contesto. In casi in cui i processi occupano i lock per poco
tempo, conviene implementarli con attesa attiva, mentre la sospensione quando
occupano molto tempo.

> Task fine grained $\rightarrow$ active waiting
>
> Task coarse grained $\rightarrow$ passive waiting

Il deadlock e' una condizione che si verifica quando un thread/processo che ha
ottenuto una risorsa richiede una risorsa che e' bloccata da un'altro thread,
nello stesso momento in cui tale thread necessita della risorsa bloccata.

Uno dei modi per *rompere* la dipendenza bloccante che puo' causare un deadlock,
e' rimuovere l'aspetto bloccante del lock dei mutex. Ad esempio
`pthread_mutex_trylock()` e' una primitiva che testa se il lock e' stato preso o
meno, senza bloccare il codice. Ovviamente l'utilizzo di tale primitiva e' una
soluzione non particolarmente buona che non risolve realmente il problema alla
radice.

Le lock come detto derivano essenzialmente da un oggetto piu' generico che e' il
semaforo. Un semaforo e' un oggetto che supporta due operazioni principali
indivisibili `P` e `V`. Possiamo descrivere il semaforo come una variabile
arbitraria che viene inizializzata ad un valore. La semantica di `P` e' quella
di decrementare il valore di uno, mentre quella di `V` e' quella di
incrementarlo di uno. La peculiarita' e' che quando un processo/thread cerca di
utilizzare `P` quando il valore e' a $0$ (e il risultato sarebbe
conseguentemente $< 0$) viene bloccato fino a quando il valore non e' $>0$
(cioe' un'altro processo/thread ha incrementato la variabilec con `V`).
Possiamo quindi notare come una lock sia semplicemente un semaforo impostato con
valore iniziale a 1.

Un *monitor* e' un'altro costrutto di sincronizzazione che permette ai threads
di avere mutua esclusione, con la possiblita' di sospendersi all'interno di essa
per aspettare una determinata condizione. Un monitor consiste in una **lock** e
una **condition variable**. Le condition variables sono essenzialmente dei
contenitori di threads che aspettano una determinata condizione. I monitor
provvedono dei meccanismi di sincronizzazione che permettono ai thread che hanno
acquisito il lock di rilasciarlo temporaneamente in modo che una determinata
condizione possa verificarsi. In Pthread questa operazione e' codificata dalla
funzione `pthread_cond_wait(condition, lock)`, che mette il thread in stato
*wait* fino a quando `condition` non e' vera, rilasciando il `lock` del monitor.
Con la funzione `pthread_cond_signal(condition)` si sveglia invece un qualsiasi
thread che e' bloccato su quella condizione. Il thread scelto dipende dalle
policy del sistema, per cui non possiamo determinarlo a priori.
La funzione `pthread_cond_broadcast(condition)` e' invece una variante della
signal che permette di svegliare tutti i threads.

> Alternativamente possiamo definire un monitor come una classe, oggetto o modulo
  thread-safe con un lock (o mutex) che permette l'accesso sicuro ad un metodo o
  ad una variabile in modo mutualmente esclusivo. Semplicemente permette a dei
  metodi di avere una lock intrinseca in modo che solo un processo/thread possa
  eseguire il codice contenuto contemporaneamente. Inoltre, all'interno di ogni
  metodo e' possibile dare il controllo ad altri threads in modo da aspettare il
  verificarsi di una determinata condizione (tramite condition variables).

## Analisi delle dipendenze
