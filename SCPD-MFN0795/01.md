# Metriche di performance
Le metriche di performance permettono di dare una stima sulla performance dei
sistemi di calcolo paralleli e distribuiti. La metrica di performance piu'
importante per tale scopo e' lo **speedup factor**.

## Speedup Factor (Strong Scaling)
Lo speedup factor e' una misura che indica quanto e' il miglioramento delle
prestazioni (in termini di tempo) che si ottiene per risolvere un problema ben
definito a priori, utilizzando $p$ processori anziche' uno singolo.
$$
S(N) = \frac{t_s}{t_p}
$$
dove:

* $t_s$ e' il tempo di esecuzione utilizzando un singolo processore (migliore
  esecuzione sequenziale)
* $t_p$ e' il tempo di esecuzione utilizzando $N$ processori

E' necessario specificare che "processori" deve essere inteso nella sua
accezione piu' generale (e quindi come unita' di computazione a livello
astratto). Non si specifica se tali sono core di un processore, processori
differenti oppure addirittura macchine differenti.  Fatta questa premessa,
pero', vien da se che il confronto deve essere fatto utilizzando coerentemente
la stessa unita' di computazione per entrambe le misurazioni. Ad esempio, se si
confrontasse un singolo processore con un clock piu' alto rispetto ai $p$
processori, la metrica risulterebbe inesatta.  Questo perche' le condizioni
degli esperimenti sono differenti tra loro, di fatto inserendo nella stima della
metrica dei fattori che ne influenzano la qualita'.  Un altro esempio potrebbe
essere quello di testare l'agoritmo sul singolo processore su una CPU e
successivamente quelli paralleli su una GPU.  Per rendere quindi la metrica il
piu' possibile precisa, l'unica condizione (o parametro) che viene resa
variabile per l'esperimento e' l'algoritmo. Questo perche' l'implementazione
dell'algoritmo che sfrutta il parallelismo e' spesso differente da
un'implementazione sequenziale.

>**Nota per il progetto d'esame**: *E' necessario inserire lo speedup factor
>nella relazione del progetto, scegliendo l'algoritmo sequenziale migliore e piu'
>efficiente per la soluzione del problema.  E' preferibile poi motivare la scelta
>dell'algoritmo attraverso una citazione.*

Nella maggior parte dei casi, lo speedup e' al massimo lineare, cioe' $S(N) \leq
N$. Questo perche' il tempo parallelo migliore si ottiene nel caso in cui sia
perfettamente divisibile per il numero di processori $N$, dal quale risulta che
$$
S(N) \leq \frac{t_s}{t_s / N} = N
$$
E' possibile anche ottenere casi in cui lo speedup e' superlineare, cioe' in cui
$S(p)>p$, ma cio' accade spesso per ragioni come la presenza di memoria
aggiuntiva (quale Cache e RAM) in sistemi multiprocessore e per l'impiego di
algoritmi nondeterministici.  Per esempio, in alcuni problemi il programma
potrebbe essere troppo grosso da caricare interamente in memoria su una macchina
singola. Sfruttando il fatto che sia possibile caricarlo interamente nella RAM o
nella Cache utilizzando piu' macchine, il fattore puo' diventare di conseguenza
superlineare.

>Nell'informatica moderna si sfrutta questo fattore di
>superlinearita' nel training delle reti neurali. Poiche' il training delle reti
>neurali ha un fattore di convoluzione (moltiplicazione di matrici) per cui i
>processori moderni sfruttano i cosiddetti *tensor cores*, tenendo l'intero
>dataset su cui fare il training in una memoria piu' efficiente (nelle GPU
>chiamata *shell memory*) e permetto quindi di avere delle ottimizzazioni
>superlineari in termini di speedup.  Si sfrutta quindi il fatto che i dati sono
>caricati interamente in una memoria molto veloce per ottenere uno speedup
>superlineare.

## Speedup Massimo: Legge di Amdahl
Lo speedup di tipo lineare assume che gli algoritmi che stiamo valutando siano
parallelizzabili interamente. Per questa ipotesi e' quindi possibile dividere in
$N$ parti il problema, per poi far risolvere gli $N$ sottoproblemi ottenuti da
$N$ elementi di calcolo.  Questa ipotesi pero' non e' generalmente vera poiche'
non tutti gli algoritmi sono parallelizzabili.  Si pensi ad esempio all'I/O:
molti algoritmi leggono inizialmente uno o piu' file e terminano generando in
output uno o piu' file.  La legge di Amdahl tiene conto delle sezioni non
parallelizzabili e che quindi devono essere eseguite per forza in modo
sequenziale. La serial fraction comprende qualsiasi sezione che non sia
parallelizzabile e che debba essere eseguita in modo sincrono.

![Rappresentazione grafica di un problema in cui e' presente una sezione non parallelizzabile
(*serial section*) \label{figAmdahl}](img/1_amdahl.png)

La legge di Amdahl da un upper bound dello speedup massimo (teorico) raggiungibile $S_{max}$:
$$
S_{max} = \frac{s}{(s + \frac{p}{N})}
$$
In cui

* $N$ e' il numero di processori in parallelo
* $p$ e' la sezione che viene eseguita in parallelo
* $s$ e' la sezione che viene eseguita in serie

Siccome l'intero programma e' composto dalla parte parallela e da quella
seriale, allora si ha che $s + p = 1$, per cui si ottiene infine:
$$
S_{max} = \frac{1}{s + p/N} = \frac{1}{(1 - p) + p/N}
$$
Si nota fin da subito dalla relazione che tale speedup massimo non potra' mai
essere $N$, per cui questa legge da una stima in un certo senso pessimistica.

## Speedup Massimo: Legge di Gustafson (Weak Scaling)
La legge di Gustafson e' un raffinamento della legge di Amdahl, che tiene conto
anche della scalabilita' della grandezza del problema. In generale, la grandezza
del problema e' costante nella legge di Ahmdahl, mentre nella legge di
Gufstafson viene tenuta in considerazione rendendola variabile come il numero di
processori $N$. La grandezza del problema viene fatta aumentare all'aumentare
della grandezza del sistema $N$ (numero di processori). In questo modo il tempo
di esecuzione parallelo e' costante, risultando di fatto numericamente
differente dallo speedup massimo della legge di Ahmdal. La legge di Gufstafson
e' anche chiamata *speedup factor scalato*. (speedup quando il problema viene
fatto scalare).
Ipotizziamo come fatto nel caso della legge di Amdahl, che un programma sia
compsto da una parte parallelizzabile $p$ e una seriale $s$ (non
parallelizzabile), e che la loro somma sia l'intero programma $s + p = 1$.
Al crescere della grandezza del problema e del numero di processori $N$, il
tempo di esecuzione sequenziale e parallelo sono pari a
$$
t_s = s + Np \quad t_p = s + \frac{Np}{N}
$$
per cui se si calcola lo speedup
$$
S_{scaled}(N) = \frac{t_s}{t_p} = \frac{s + Np}{s + p} = s + pN
$$
ottenendo cosi' la legge di Gustafson.
Notiamo che ci sono due assunzioni principali in questa legge:

* Il tempo di esecuzione parallelo e' costante
* Il tempo di esecuzione della parte seriale e' costante e non dipende da $p$
