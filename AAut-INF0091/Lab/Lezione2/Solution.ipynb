{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6245378e",
   "metadata": {},
   "source": [
    "# Exercises solutions\n",
    "First thing first, we need to import the relevant libraries and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5d035aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e5f6dd",
   "metadata": {},
   "source": [
    "We then load the dataset and split it into test set and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e1939e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 88  70  87  36  21   9 103  67 117  47]\n"
     ]
    }
   ],
   "source": [
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Setup seed\n",
    "rngs = 0\n",
    "np.random.seed(rngs)\n",
    "\n",
    "# Create a uniform distribution of indexes\n",
    "indices = np.random.permutation(len(iris.data))\n",
    "# Split the dataset\n",
    "indices_train = indices[:-10]\n",
    "indices_test = indices[-10:]\n",
    "\n",
    "X_train = iris.data[indices_train]\n",
    "X_test = iris.data[indices_test]\n",
    "y_train = iris.target[indices_train]\n",
    "y_test = iris.target[indices_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4b68c6",
   "metadata": {},
   "source": [
    "# Inflating the dataset\n",
    "To solve the first point of the exercise, we need to *artificially inflate* the dataset. The idea is to create a new train dataset, in which each example is repeated according to its corresponding class cost.\n",
    "In order to do that, we first specify a cost array, where the $i^{th}$ element corresponds to the cost assigned to the $i^{th}$ class. We then create an array that specify for every element how many times it has to be repeated, which will then be used by the `np.repeat` function. With that function we can inflate the dataset by inflating indexes that corresponds to instances on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "348edb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = np.array([10, 1, 1])\n",
    "inflation_factors = costs[y_train]\n",
    "# ai stands for: artificially inflated\n",
    "indices_train_ai = np.repeat(indices_train, inflation_factors)\n",
    "\n",
    "# We now get the real inflated dataset by using inflated indexes\n",
    "X_train_ai = iris.data[indices_train_ai]\n",
    "y_train_ai = iris.target[indices_train_ai]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd1f620",
   "metadata": {},
   "source": [
    "# Defining the models\n",
    "Essentially 2 models will be trained: one on the *artificially inflated* dataset, while the other one will be trained on the original training set, but with the cost hyperparameter set to match the inflated version.\n",
    "According to the theory, those models should ouput the same predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a6c8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 300\n",
    "impurity_measure = \"entropy\"\n",
    "minimum_samples = 5\n",
    "weights = { i:costs[i] for i in range(0, len(costs)) } # transform costs inot a suitable form for the library\n",
    "\n",
    "clf_hp = tree.DecisionTreeClassifier(criterion=impurity_measure, random_state=seed, min_samples_leaf=minimum_samples, class_weight=weights)\n",
    "clf_ai = tree.DecisionTreeClassifier(criterion=impurity_measure, random_state=seed, min_samples_leaf=minimum_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc539944",
   "metadata": {},
   "source": [
    "We now train the model and save their predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f6a109e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_hp.fit(X_train, y_train)\n",
    "clf_ai.fit(X_train_ai, y_train_ai)\n",
    "\n",
    "results_hp = clf_hp.predict(X_test)\n",
    "results_ai = clf_hp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50bfe2c",
   "metadata": {},
   "source": [
    "As a last step, we evaluate the performances of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3e8133b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[1 2 1 0 0 0 2 1 2 0]\n",
      "[1 2 1 0 0 0 2 1 2 0]\n",
      "True classes:\n",
      "[1 1 1 0 0 0 2 1 2 0]\n",
      "Accuracy score (Costs on hyperparameters): 0.9\n",
      "Accuracy score (Costs artificially inflating): 0.9\n",
      "F1 score (Costs on hyperparameters): 0.8857142857142858\n",
      "F1 score (Costs artificially inflating): 0.8857142857142858\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions:\")\n",
    "print(results_hp)\n",
    "print(results_ai)\n",
    "print(\"True classes:\")\n",
    "print(y_test) \n",
    "# We can see that results are in accordance with the theory\n",
    "\n",
    "acc_hp = accuracy_score(y_test, results_hp)\n",
    "acc_ai = accuracy_score(y_test, results_ai)\n",
    "print(\"Accuracy score (Costs on hyperparameters): \"+ str(acc_hp))\n",
    "print(\"Accuracy score (Costs artificially inflating): \"+ str(acc_ai))\n",
    "f1_hp = f1_score(y_test, results_hp, average='macro')\n",
    "f1_ai = f1_score(y_test, results_hp, average='macro')\n",
    "print(\"F1 score (Costs on hyperparameters): \"+str(f1_hp))\n",
    "print(\"F1 score (Costs artificially inflating): \"+str(f1_ai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca4149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
